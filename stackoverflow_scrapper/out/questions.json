[
    {
        "_id": 0,
        "_Pregunta__titulo": "How to make good reproducible pandas examples",
        "_Pregunta__fecha": "2017-05-23 11:54:58Z",
        "_Pregunta__descripcion": "\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        This question's answers are a community effort. Edit existing answers to improve this post. It is not currently accepting new answers or interactions.\n                        \n                    \n                \n            \n        \n\n\n    \n\nHaving spent a decent amount of time watching both the r and pandas tags on SO, the impression that I get is that pandas questions are less likely to contain reproducible data. This is something that the R community has been pretty good about encouraging, and thanks to guides like this, newcomers are able to get some help on putting together these examples. People who are able to read these guides and come back with reproducible data will often have much better luck getting answers to their questions.\n\nHow can we create good reproducible examples for pandas questions? Simple dataframes can be put together, e.g.:\n\nimport pandas as pd\ndf = pd.DataFrame({'user': ['Bob', 'Jane', 'Alice'], \n                   'income': [40000, 50000, 42000]})\n\n\nBut many example datasets need more complicated structure, e.g.:\n\n\ndatetime indices or data\nMultiple categorical variables (is there an equivalent to R's expand.grid() function, which produces all possible combinations of some given variables?)\nMultiIndex or Panel data\n\n\nFor datasets that are hard to mock up using a few lines of code, is there an equivalent to R's dput() that allows you to generate copy-pasteable code to regenerate your datastructure?\n    ",
        "_Pregunta__votes": 220,
        "_Pregunta__tags": [
            "pandas",
            "python",
            "r"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 0,
            "_Respuesta__fecha": "2021-07-24 20:43:05Z",
            "_Respuesta__descripcion": "\nNote: The ideas here are pretty generic for Stack Overflow, indeed questions.\nDisclaimer: Writing a good question is hard.\nThe Good:\n\ndo include small* example DataFrame, either as runnable code:\n  In [1]: df = pd.DataFrame([[1, 2], [1, 3], [4, 6]], columns=['A', 'B'])\n\nor make it \"copy and pasteable\" using pd.read_clipboard(sep='\\s\\s+'), you can format the text for Stack Overflow highlight and use Ctrl+K (or prepend four spaces to each line), or place three tildes above and below your code with your code unindented:\n  In [2]: df\n  Out[2]:\n     A  B\n  0  1  2\n  1  1  3\n  2  4  6\n\ntest pd.read_clipboard(sep='\\s\\s+') yourself.\n* I really do mean small, the vast majority of example DataFrames could be fewer than 6 rowscitation needed, and I bet I can do it in 5 rows. Can you reproduce the error with df = df.head(), if not fiddle around to see if you can make up a small DataFrame which exhibits the issue you are facing.\n* Every rule has an exception, the obvious one is for performance issues  (in which case definitely use %timeit and possibly %prun), where you should generate (consider using np.random.seed so we have the exact same frame): df = pd.DataFrame(np.random.randn(100000000, 10)). Saying that, \"make this code fast for me\" is not strictly on topic for the site...\n\nwrite out the outcome you desire (similarly to above)\n  In [3]: iwantthis\n  Out[3]:\n     A  B\n  0  1  5\n  1  4  6\n\nExplain what the numbers come from: the 5 is sum of the B column for the rows where A is 1.\n\ndo show the code you've tried:\n  In [4]: df.groupby('A').sum()\n  Out[4]:\n     B\n  A\n  1  5\n  4  6\n\nBut say what's incorrect: the A column is in the index rather than a column.\n\ndo show you've done some research (search the documentation, search Stack\u00a0Overflow), and give a summary:\n\nThe docstring for sum simply states \"Compute sum of group values\"\n\n\nThe groupby documentation doesn't give any examples for this.\n\nAside: the answer here is to use df.groupby('A', as_index=False).sum().\n\nif it's relevant that you have Timestamp columns, e.g. you're resampling or something, then be explicit and apply pd.to_datetime to them for good measure**.\n  df['date'] = pd.to_datetime(df['date']) # this column ought to be date..\n\n** Sometimes this is the issue itself: they were strings.\n\n\nThe Bad:\n\ndon't include a MultiIndex, which we can't copy and paste (see above). This is kind of a grievance with Pandas' default display, but nonetheless annoying:\n  In [11]: df\n  Out[11]:\n       C\n  A B\n  1 2  3\n    2  6\n\nThe correct way is to include an ordinary DataFrame with a set_index call:\n  In [12]: df = pd.DataFrame([[1, 2, 3], [1, 2, 6]], columns=['A', 'B', 'C']).set_index(['A', 'B'])\n\n  In [13]: df\n  Out[13]:\n       C\n  A B\n  1 2  3\n    2  6\n\n\ndo provide insight to what it is when giving the outcome you want:\n     B\n  A\n  1  1\n  5  0\n\nBe specific about how you got the numbers (what are they)... double check they're correct.\n\nIf your code throws an error, do include the entire stack trace (this can be edited out later if it's too noisy). Show the line number (and the corresponding line of your code which it's raising against).\n\n\nThe Ugly:\n\ndon't link to a CSV file we don't have access to (ideally don't link to an external source at all...)\n  df = pd.read_csv('my_secret_file.csv')  # ideally with lots of parsing options\n\nMost data is proprietary we get that: Make up similar data and see if you can reproduce the problem (something small).\n\ndon't explain the situation vaguely in words, like you have a DataFrame which is \"large\", mention some of the column names in passing (be sure not to mention their dtypes). Try and go into lots of detail about something which is completely meaningless without seeing the actual context. Presumably no one is even going to read to the end of this paragraph.\nEssays are bad, it's easier with small examples.\n\ndon't include 10+ (100+??) lines of data munging before getting to your actual question.\nPlease, we see enough of this in our day jobs. We want to help, but not like this....\nCut the intro, and just show the relevant DataFrames (or small versions of them) in the step which is causing you trouble.\n\n\nAnyway, have fun learning Python, NumPy and Pandas!\n    ",
            "_Respuesta__votes": 402,
            "comentarios": [
                {
                    "_id": 0,
                    "_Comentario__descripcion": "+1 for the pd.read_clipboard(sep='\\s\\s+') tip. When I post SO questions that need a special but easily shared dataframe, like this one I build it in excel, copy it to my clipboard, then instruct SOers to do the same. Saves so much time!",
                    "_Comentario__fecha": "2016-04-13 17:32:12Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "zelusp"
                },
                {
                    "_id": 1,
                    "_Comentario__descripcion": "the pd.read_clipboard(sep='\\s\\s+') suggestion does not seem to work if you're using Python on a remote server, which is where a lot of large data sets live.",
                    "_Comentario__fecha": "2016-12-09 17:50:15Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "user5359531"
                },
                {
                    "_id": 2,
                    "_Comentario__descripcion": "Why pd.read_clipboard(sep='\\s\\s+'), and not a simpler pd.read_clipboard() (with the default \u2018s+\u2019)? The first need at least 2 whitespace characters, which may cause problems if there is only 1 (e. g. see such in the @JohnE 's answer).",
                    "_Comentario__fecha": "2018-12-26 22:32:33Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "MarianD"
                },
                {
                    "_id": 3,
                    "_Comentario__descripcion": "@MarianD the reason that \\s\\s+ is so popular is that there is often one e.g. in a column name, but multiple is rarer, and pandas output nicely puts in at least two between columns. Since this is just for toy/small datasets it's pretty powerful/majority of cases. Note: tabs separated would be a different story, though stackoverflow replaces tabs with spaces, but if you have a tsv then just use \\t.",
                    "_Comentario__fecha": "2018-12-27 20:45:57Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "Andy Hayden"
                },
                {
                    "_id": 4,
                    "_Comentario__descripcion": "Ugh, i always use pd.read_clipboard(), when their are spaces, i do: pd.read_clipboard(sep='\\s+{2,}', engine='python') :P",
                    "_Comentario__fecha": "2019-06-10 11:26:36Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "U12-Forward"
                }
            ],
            "_Respuesta__usuario": "Andy Hayden"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            1,
            2,
            3,
            4,
            5
        ],
        "comentarios": [
            {
                "_id": 14,
                "_Comentario__descripcion": "If you copy the output of printing, most of the time answerers can use read_clipboard()... except for MultiIndex :s. Saying that, dict is good addition",
                "_Comentario__fecha": "2013-11-20 23:39:54Z, License: CC BY-SA 3.0",
                "_Comentario__usuario": "Andy Hayden"
            },
            {
                "_id": 15,
                "_Comentario__descripcion": "In addition to what Andy said, I think copy-pasting df.head(N).to_dict(), where N is some reasonable number is a good way to go. Bonus +1's for adding pretty-line breaks to the output. For timestamps, you'll typically just need to add from pandas import Timestamp to the top of the code.",
                "_Comentario__fecha": "2013-11-20 23:51:38Z, License: CC BY-SA 3.0",
                "_Comentario__usuario": "Paul H"
            }
        ],
        "_Pregunta__usuario": "Marius"
    },
    {
        "_id": 1,
        "_Pregunta__titulo": "How to test multiple variables against a single value?",
        "_Pregunta__fecha": "2021-04-11 18:39:47Z",
        "_Pregunta__descripcion": "\n                \nI'm trying to make a function that will compare multiple variables to an integer and output a string of three letters. I was wondering if there was a way to translate this into Python. So say:\n\nx = 0\ny = 1\nz = 3\nmylist = []\n\nif x or y or z == 0 :\n    mylist.append(\"c\")\nif x or y or z == 1 :\n    mylist.append(\"d\")\nif x or y or z == 2 :\n    mylist.append(\"e\")\nif x or y or z == 3 : \n    mylist.append(\"f\")\n\n\nwhich would return a list of:\n\n[\"c\", \"d\", \"f\"]\n\n\nIs something like this possible?\n    ",
        "_Pregunta__votes": 744,
        "_Pregunta__tags": [
            "comparison",
            "match",
            "python",
            "boolean-logic",
            "if-statement"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 6,
            "_Respuesta__fecha": "2021-04-02 01:51:27Z",
            "_Respuesta__descripcion": "\nYou misunderstand how boolean expressions work; they don't work like an English sentence and guess that you are talking about the same comparison for all names here. You are looking for:\nif x == 1 or y == 1 or z == 1:\n\nx and y are otherwise evaluated on their own (False if 0, True otherwise).\nYou can shorten that using a containment test against a tuple:\nif 1 in (x, y, z):\n\nor better still:\nif 1 in {x, y, z}:\n\nusing a set to take advantage of the constant-cost membership test (i.e. in takes a fixed amount of time whatever the left-hand operand is).\nExplanation\nWhen you use or, python sees each side of the operator as separate expressions. The expression x or y == 1 is treated as first a boolean test for x, then if that is False, the expression y == 1 is tested.\nThis is due to operator precedence. The or operator has a lower precedence than the == test, so the latter is evaluated first.\nHowever, even if this were not the case, and the expression x or y or z == 1 was actually interpreted as (x or y or z) == 1 instead, this would still not do what you expect it to do.\nx or y or z would evaluate to the first argument that is 'truthy', e.g. not False, numeric 0 or empty (see boolean expressions for details on what Python considers false in a boolean context).\nSo for the values x = 2; y = 1; z = 0, x or y or z would resolve to 2, because that is the first true-like value in the arguments. Then 2 == 1 would be False, even though y == 1 would be True.\nThe same would apply to the inverse; testing multiple values against a single variable; x == 1 or 2 or 3 would fail for the same reasons. Use x == 1 or x == 2 or x == 3 or x in {1, 2, 3}.\n    ",
            "_Respuesta__votes": 991,
            "comentarios": [
                {
                    "_id": 16,
                    "_Comentario__descripcion": "I wouldn't be so quick to go for the set version.  Tuple's are very cheap to create and iterate over.  On my machine at least, tuples are faster than sets so long as the size of the tuple is around 4-8 elements.  If you have to scan more than that, use a set, but if you are looking for an item out of 2-4 possibilities, a tuple is still faster!  If you can arrange for the most likely case to be first in the tuple, the win is even bigger: (my test: timeit.timeit('0 in {seq}'.format(seq=tuple(range(9, -1, -1)))))",
                    "_Comentario__fecha": "2013-10-24 15:27:12Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "SingleNegationElimination"
                },
                {
                    "_id": 17,
                    "_Comentario__descripcion": "@dequestarmappartialsetattr: In Python 3.3 and up, the set is stored as a constant, bypassing the creation time altogether, eliminating the creation time. Tuples can be cheap to create as Python caches a bundle of them to avoid memory churn, making that the biggest difference with sets here.",
                    "_Comentario__fecha": "2013-10-24 15:29:51Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Martijn Pieters\u2666"
                },
                {
                    "_id": 18,
                    "_Comentario__descripcion": "@dequestarmappartialsetattr: If you time just the membership test, for integers sets and tuples are equally fast for the ideal scenario; matching the first element. After that tuples lose out to sets.",
                    "_Comentario__fecha": "2013-10-24 15:37:11Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Martijn Pieters\u2666"
                },
                {
                    "_id": 19,
                    "_Comentario__descripcion": "@MartijnPieters: Using the set literal notation for this test isn't a savings unless the contents of the set literal are also literals, right? if 1 in {x, y, z}: can't cache the set, because x, y and z could change, so either solution needs to build a tuple or set from scratch, and I suspect whatever lookup savings you might get when checking for membership would be swamped by greater set creation time.",
                    "_Comentario__fecha": "2016-09-04 00:37:09Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "ShadowRanger"
                },
                {
                    "_id": 20,
                    "_Comentario__descripcion": "@ShadowRanger: yes, peephole optimisation (be it for in [...] or in {...}) only works if the contents of the list or set are immutable literals too.",
                    "_Comentario__fecha": "2016-09-04 07:58:07Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Martijn Pieters\u2666"
                }
            ],
            "_Respuesta__usuario": "Martijn Pieters"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16,
            17,
            18,
            19,
            20,
            21,
            22,
            23,
            24,
            25,
            26,
            27,
            28,
            29,
            30,
            31,
            32,
            33
        ],
        "comentarios": [
            {
                "_id": 42,
                "_Comentario__descripcion": "use 1 in (tuple)",
                "_Comentario__fecha": "2017-12-05 21:49:51Z, License: CC BY-SA 3.0",
                "_Comentario__usuario": "NA"
            },
            {
                "_id": 43,
                "_Comentario__descripcion": "When you want to evaluate a list of statements in a any/all manner you can use any/all functions. For example: all([1, 2, 3, 4, False]) will return False all([True, 1, 2, 3]) will return True any([False, 0, 0, False]) will return False any([False, 0, True, False]) will return True",
                "_Comentario__fecha": "2018-06-04 16:17:30Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "eddd"
            },
            {
                "_id": 44,
                "_Comentario__descripcion": "This question is a very popular duplicate target, but I think it's suboptimal for that purpose. Most people try to do something like if x == 0 or 1:, which is of course similar to if x or y == 0:, but might be a little confusing for newbies nonetheless. Given the sheer volume of \"Why isn't my x == 0 or 1 working?\" questions, I would much rather use this question as our canonical duplicate target for these questions.",
                "_Comentario__fecha": "2019-04-10 10:06:05Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "Aran-Fey"
            },
            {
                "_id": 45,
                "_Comentario__descripcion": "Take extra care when comparing to \"falsey\" values like 0, 0.0 or False. You can easily write wrong code which gives the \"right\" answer.",
                "_Comentario__fecha": "2019-04-10 10:09:25Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "smci"
            },
            {
                "_id": 46,
                "_Comentario__descripcion": "For the opposite, see Comparing a string to multiple items in Python",
                "_Comentario__fecha": "2020-01-08 10:27:08Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "tripleee"
            }
        ],
        "_Pregunta__usuario": "user1877442"
    },
    {
        "_id": 2,
        "_Pregunta__titulo": "Asking the user for input until they give a valid response",
        "_Pregunta__fecha": "2021-03-31 17:54:23Z",
        "_Pregunta__descripcion": "\n                \nI am writing a program that accepts an input from the user.\n\n#note: Python 2.7 users should use `raw_input`, the equivalent of 3.X's `input`\nage = int(input(\"Please enter your age: \"))\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n\n\nThe program works as expected as long as the the user enters meaningful data. \n\nC:\\Python\\Projects> canyouvote.py\nPlease enter your age: 23\nYou are able to vote in the United States!\n\n\nBut it fails if the user enters invalid data:\n\nC:\\Python\\Projects> canyouvote.py\nPlease enter your age: dickety six\nTraceback (most recent call last):\n  File \"canyouvote.py\", line 1, in <module>\n    age = int(input(\"Please enter your age: \"))\nValueError: invalid literal for int() with base 10: 'dickety six'\n\n\nInstead of crashing, I would like the program to ask for the input again. Like this:\n\nC:\\Python\\Projects> canyouvote.py\nPlease enter your age: dickety six\nSorry, I didn't understand that.\nPlease enter your age: 26\nYou are able to vote in the United States!\n\n\nHow can I make the program ask for valid inputs instead of crashing when non-sensical data is entered?\n\nHow can I reject values like -1, which is a valid int, but nonsensical in this context?\n    ",
        "_Pregunta__votes": 656,
        "_Pregunta__tags": [
            "python"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 34,
            "_Respuesta__fecha": "2020-06-06 17:56:58Z",
            "_Respuesta__descripcion": "\nThe simplest way to accomplish this is to put the input method in a while loop. Use continue when you get bad input, and break out of the loop when you're satisfied.\n\nWhen Your Input Might Raise an Exception\n\nUse try and except to detect when the user enters data that can't be parsed.\n\nwhile True:\n    try:\n        # Note: Python 2.x users should use raw_input, the equivalent of 3.x's input\n        age = int(input(\"Please enter your age: \"))\n    except ValueError:\n        print(\"Sorry, I didn't understand that.\")\n        #better try again... Return to the start of the loop\n        continue\n    else:\n        #age was successfully parsed!\n        #we're ready to exit the loop.\n        break\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n\n\nImplementing Your Own Validation Rules\n\nIf you want to reject values that Python can successfully parse, you can add your own validation logic.\n\nwhile True:\n    data = input(\"Please enter a loud message (must be all caps): \")\n    if not data.isupper():\n        print(\"Sorry, your response was not loud enough.\")\n        continue\n    else:\n        #we're happy with the value given.\n        #we're ready to exit the loop.\n        break\n\nwhile True:\n    data = input(\"Pick an answer from A to D:\")\n    if data.lower() not in ('a', 'b', 'c', 'd'):\n        print(\"Not an appropriate choice.\")\n    else:\n        break\n\n\nCombining Exception Handling and Custom Validation\n\nBoth of the above techniques can be combined into one loop.\n\nwhile True:\n    try:\n        age = int(input(\"Please enter your age: \"))\n    except ValueError:\n        print(\"Sorry, I didn't understand that.\")\n        continue\n\n    if age < 0:\n        print(\"Sorry, your response must not be negative.\")\n        continue\n    else:\n        #age was successfully parsed, and we're happy with its value.\n        #we're ready to exit the loop.\n        break\nif age >= 18: \n    print(\"You are able to vote in the United States!\")\nelse:\n    print(\"You are not able to vote in the United States.\")\n\n\nEncapsulating it All in a Function\n\nIf you need to ask your user for a lot of different values, it might be useful to put this code in a function, so you don't have to retype it every time.\n\ndef get_non_negative_int(prompt):\n    while True:\n        try:\n            value = int(input(prompt))\n        except ValueError:\n            print(\"Sorry, I didn't understand that.\")\n            continue\n\n        if value < 0:\n            print(\"Sorry, your response must not be negative.\")\n            continue\n        else:\n            break\n    return value\n\nage = get_non_negative_int(\"Please enter your age: \")\nkids = get_non_negative_int(\"Please enter the number of children you have: \")\nsalary = get_non_negative_int(\"Please enter your yearly earnings, in dollars: \")\n\n\nPutting It All Together\n\nYou can extend this idea to make a very generic input function:\n\ndef sanitised_input(prompt, type_=None, min_=None, max_=None, range_=None):\n    if min_ is not None and max_ is not None and max_ < min_:\n        raise ValueError(\"min_ must be less than or equal to max_.\")\n    while True:\n        ui = input(prompt)\n        if type_ is not None:\n            try:\n                ui = type_(ui)\n            except ValueError:\n                print(\"Input type must be {0}.\".format(type_.__name__))\n                continue\n        if max_ is not None and ui > max_:\n            print(\"Input must be less than or equal to {0}.\".format(max_))\n        elif min_ is not None and ui < min_:\n            print(\"Input must be greater than or equal to {0}.\".format(min_))\n        elif range_ is not None and ui not in range_:\n            if isinstance(range_, range):\n                template = \"Input must be between {0.start} and {0.stop}.\"\n                print(template.format(range_))\n            else:\n                template = \"Input must be {0}.\"\n                if len(range_) == 1:\n                    print(template.format(*range_))\n                else:\n                    expected = \" or \".join((\n                        \", \".join(str(x) for x in range_[:-1]),\n                        str(range_[-1])\n                    ))\n                    print(template.format(expected))\n        else:\n            return ui\n\n\nWith usage such as:\n\nage = sanitised_input(\"Enter your age: \", int, 1, 101)\nanswer = sanitised_input(\"Enter your answer: \", str.lower, range_=('a', 'b', 'c', 'd'))\n\n\nCommon Pitfalls, and Why you Should Avoid Them\n\nThe Redundant Use of Redundant input Statements\n\nThis method works but is generally considered poor style:\n\ndata = input(\"Please enter a loud message (must be all caps): \")\nwhile not data.isupper():\n    print(\"Sorry, your response was not loud enough.\")\n    data = input(\"Please enter a loud message (must be all caps): \")\n\n\nIt might look attractive initially because it's shorter than the while True method, but it violates the Don't Repeat Yourself principle of software development. This increases the likelihood of bugs in your system. What if you want to backport to 2.7 by changing input to raw_input, but accidentally change only the first input above? It's a SyntaxError just waiting to happen.\n\nRecursion Will Blow Your Stack\n\nIf you've just learned about recursion, you might be tempted to use it in get_non_negative_int so you can dispose of the while loop.\n\ndef get_non_negative_int(prompt):\n    try:\n        value = int(input(prompt))\n    except ValueError:\n        print(\"Sorry, I didn't understand that.\")\n        return get_non_negative_int(prompt)\n\n    if value < 0:\n        print(\"Sorry, your response must not be negative.\")\n        return get_non_negative_int(prompt)\n    else:\n        return value\n\n\nThis appears to work fine most of the time, but if the user enters invalid data enough times, the script will terminate with a RuntimeError: maximum recursion depth exceeded. You may think \"no fool would make 1000 mistakes in a row\", but you're underestimating the ingenuity of fools!\n    ",
            "_Respuesta__votes": 852,
            "comentarios": [
                {
                    "_id": 47,
                    "_Comentario__descripcion": "Its fun reading it with many examples, kudos. Underrated lesson: \"Don't underestimate the ingenuity of fools!\"",
                    "_Comentario__fecha": "2017-01-03 02:02:47Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "vpibano"
                },
                {
                    "_id": 48,
                    "_Comentario__descripcion": "Not only would I have upvoted both the Q&A anyway, as they're great, but you sealed the deal with \"dickety six\". Well done, @Kevin.",
                    "_Comentario__fecha": "2018-02-02 15:58:58Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "erekalper"
                },
                {
                    "_id": 49,
                    "_Comentario__descripcion": "Don't estimate the ingenuity of fools... and clever attackers. A DOS attack would be easiest for this sort of thing, but others may be possible.",
                    "_Comentario__fecha": "2019-04-28 02:53:37Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "Solomon Ucko"
                },
                {
                    "_id": 50,
                    "_Comentario__descripcion": "@JArunMani I don't think it would be poor style, but might be a little less readable. You will indeed have only one input per loop and the loop will become very short, but the condition might become pretty long...",
                    "_Comentario__fecha": "2020-05-09 08:40:15Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "Tomerikoo"
                },
                {
                    "_id": 51,
                    "_Comentario__descripcion": "@laundmo,certainly I release the code blocks that I wrote into the public domain. Feel free to use them in any context, without my explicit permission or knowledge. Regarding the non-code-block segments, If you want to paste my entire answer into a \"Learn Python\" book you're writing, let's talk royalties ;-)",
                    "_Comentario__fecha": "2020-07-24 13:50:12Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "Kevin"
                }
            ],
            "_Respuesta__usuario": "ANON"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            35,
            36,
            37,
            38,
            39,
            40,
            41,
            42,
            43,
            44,
            45,
            46,
            47,
            48,
            49,
            50,
            51,
            52,
            53,
            54,
            55,
            56
        ],
        "comentarios": [
            {
                "_id": 76,
                "_Comentario__descripcion": "I think there's a bug in one of your comments, it should read #note: Python 2.7 users should damn-well get their act together and update :-)",
                "_Comentario__fecha": "2020-09-08 02:05:21Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "paxdiablo"
            }
        ],
        "_Pregunta__usuario": "ANON"
    },
    {
        "_id": 3,
        "_Pregunta__titulo": "How do I create variable variables?",
        "_Pregunta__fecha": "2021-01-13 02:01:54Z",
        "_Pregunta__descripcion": "\n                \nHow do I accomplish variable variables in Python?\nHere is an elaborative manual entry, for instance: Variable variables\nI hear this is a bad idea in general though, and it is a security hole in PHP. Is that true?\n    ",
        "_Pregunta__votes": 452,
        "_Pregunta__tags": [
            "python",
            "variable-variables"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 57,
            "_Respuesta__fecha": "2020-06-12 16:56:19Z",
            "_Respuesta__descripcion": "\nYou can use dictionaries to accomplish this. Dictionaries are stores of keys and values. \n\n>>> dct = {'x': 1, 'y': 2, 'z': 3}\n>>> dct\n{'y': 2, 'x': 1, 'z': 3}\n>>> dct[\"y\"]\n2\n\n\nYou can use variable key names to achieve the effect of variable variables without the security risk.\n\n>>> x = \"spam\"\n>>> z = {x: \"eggs\"}\n>>> z[\"spam\"]\n'eggs'\n\n\nFor cases where you're thinking of doing something like\n\nvar1 = 'foo'\nvar2 = 'bar'\nvar3 = 'baz'\n...\n\n\na list may be more appropriate than a dict. A list represents an ordered sequence of objects, with integer indices:\n\nlst = ['foo', 'bar', 'baz']\nprint(lst[1])           # prints bar, because indices start at 0\nlst.append('potatoes')  # lst is now ['foo', 'bar', 'baz', 'potatoes']\n\n\nFor ordered sequences, lists are more convenient than dicts with integer keys, because lists support iteration in index order, slicing, append, and other operations that would require awkward key management with a dict.\n    ",
            "_Respuesta__votes": 365,
            "comentarios": [],
            "_Respuesta__usuario": "ANON"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            58,
            59,
            60,
            61,
            62,
            63,
            64,
            65,
            66,
            67,
            68,
            69,
            70,
            71,
            72,
            73
        ],
        "comentarios": [
            {
                "_id": 83,
                "_Comentario__descripcion": "it's the maintainance and debugging aspects that cause the horror. Imagine trying to find out where variable 'foo' changed when there's no place in your code where you actually change 'foo'. Imagine further that it's someone else's code that you have to maintain... OK, you can go to your happy place now.",
                "_Comentario__fecha": "2009-09-03 14:28:55Z, License: CC BY-SA 2.5",
                "_Comentario__usuario": "glenn jackman"
            },
            {
                "_id": 84,
                "_Comentario__descripcion": "A further pitfall that hasn't been mentioned so far is if such a dynamically-created variable has the same name as a variable used in your logic. You essentially open up your software as a hostage to the input it is given.",
                "_Comentario__fecha": "2014-12-19 10:50:29Z, License: CC BY-SA 3.0",
                "_Comentario__usuario": "holdenweb"
            },
            {
                "_id": 85,
                "_Comentario__descripcion": "All the responses here assume you have access to the base variables you want to access dynamically by name, which is not always the case. I think the most general approach to reproduce the example behaviour in PHP is to use eval() like this:  var_name = 'foo'; bar = 5; output = eval(var_name)",
                "_Comentario__fecha": "2019-10-23 17:18:58Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "Luis Vazquez"
            },
            {
                "_id": 86,
                "_Comentario__descripcion": "You can modify your global and local variables by accessing the underlying dictionaries for them; it's a horrible idea from a maintenance perspective ... but it can be done via globals().update() and locals().update() (or by saving the dict reference from either of those and using it like any other dictionary).  NOT RECOMMENDED ... but you should know that it's possible.",
                "_Comentario__fecha": "2020-03-19 09:13:59Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "Jim Dennis"
            },
            {
                "_id": 87,
                "_Comentario__descripcion": "@JimDennis actually, no it can't. Modifications to the dict returned by locals will not affect local namespaces in CPython. Which is another reason not to do it.",
                "_Comentario__fecha": "2020-05-18 22:27:27Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "juanpa.arrivillaga"
            }
        ],
        "_Pregunta__usuario": "ANON"
    },
    {
        "_id": 4,
        "_Pregunta__titulo": "Understanding slice notation",
        "_Pregunta__fecha": "2019-05-08 16:03:58Z",
        "_Pregunta__descripcion": "\n                \nI need a good explanation (references are a plus) on Python's slice notation. \n\nTo me, this notation needs a bit of picking up. \n\nIt looks extremely powerful, but I haven't quite got my head around it.\n    ",
        "_Pregunta__votes": 3958,
        "_Pregunta__tags": [
            "iterable",
            "python",
            "list",
            "slice"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 74,
            "_Respuesta__fecha": "2020-02-24 19:27:21Z",
            "_Respuesta__descripcion": "\nIt's pretty simple really:\n\na[start:stop]  # items start through stop-1\na[start:]      # items start through the rest of the array\na[:stop]       # items from the beginning through stop-1\na[:]           # a copy of the whole array\n\n\nThere is also the step value, which can be used with any of the above:\n\na[start:stop:step] # start through not past stop, by step\n\n\nThe key point to remember is that the :stop value represents the first value that is not in the selected slice. So, the difference between stop and start is the number of elements selected (if step is 1, the default).\n\nThe other feature is that start or stop may be a negative number, which means it counts from the end of the array instead of the beginning. So:\n\na[-1]    # last item in the array\na[-2:]   # last two items in the array\na[:-2]   # everything except the last two items\n\n\nSimilarly, step may be a negative number:\n\na[::-1]    # all items in the array, reversed\na[1::-1]   # the first two items, reversed\na[:-3:-1]  # the last two items, reversed\na[-3::-1]  # everything except the last two items, reversed\n\n\nPython is kind to the programmer if there are fewer items than you ask for. For example, if you ask for a[:-2] and a only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen.\n\nRelation to slice() object\n\nThe slicing operator [] is actually being used in the above code with a slice() object using the : notation (which is only valid within []), i.e.:\n\na[start:stop:step]\n\n\nis equivalent to:\n\na[slice(start, stop, step)]\n\n\nSlice objects also behave slightly differently depending on the number of arguments, similarly to range(), i.e. both slice(stop) and slice(start, stop[, step]) are supported.\nTo skip specifying a given argument, one might use None, so that e.g. a[start:] is equivalent to a[slice(start, None)] or a[::-1] is equivalent to a[slice(None, None, -1)].\n\nWhile the :-based notation is very helpful for simple slicing, the explicit use of slice() objects simplifies the programmatic generation of slicing.\n    ",
            "_Respuesta__votes": 5549,
            "comentarios": [
                {
                    "_id": 88,
                    "_Comentario__descripcion": "Slicing builtin types returns a copy but that's not universal.  Notably, slicing NumPy arrays returns a view that shares memory with the original.",
                    "_Comentario__fecha": "2013-09-23 00:13:06Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Beni Cherniavsky-Paskin"
                },
                {
                    "_id": 89,
                    "_Comentario__descripcion": "This is a beautiful answer with the votes to prove it, but it misses one thing: you can substitute None for any of the empty spaces. For example [None:None] makes a whole copy. This is useful when you need to specify the end of the range using a variable and need to include the last item.",
                    "_Comentario__fecha": "2019-01-16 18:49:18Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "Mark Ransom"
                },
                {
                    "_id": 90,
                    "_Comentario__descripcion": "Note that contrary to usual Python slices (see above), in Pandas Dataframes both the start and the stop are included when present in the index. For further info see the Pandas indexing documentation.",
                    "_Comentario__fecha": "2019-05-29 12:54:33Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "vreyespue"
                },
                {
                    "_id": 91,
                    "_Comentario__descripcion": "What really annoys me is that python says that when you don't set the start and the end, they default to 0 and the length of sequence. So, in theory, when you use \"abcdef\"[::-1] it should be transformed to \"abcdef\"[0:6:-1], but these two expressions does not get the same output. I feel that something is missing in python documentation since the creation of the language.",
                    "_Comentario__fecha": "2019-06-30 14:00:10Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "axell-brendow"
                },
                {
                    "_id": 92,
                    "_Comentario__descripcion": "And I know that \"abcdef\"[::-1] is transformed to \"abcdef\"[6:-7:-1], so, the best way to explain would be: let len be the length of the sequence. If step is positive, the defaults for start and end are 0 and len. Else if step is negative, the defaults for start and end are len and -len - 1.",
                    "_Comentario__fecha": "2019-06-30 14:22:35Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "axell-brendow"
                }
            ],
            "_Respuesta__usuario": "Greg Hewgill"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            75,
            76,
            77,
            78,
            79,
            80,
            81,
            82,
            83,
            84,
            85,
            86,
            87,
            88,
            89,
            90,
            91,
            92,
            93,
            94,
            95,
            96,
            97,
            98,
            99,
            100,
            101,
            102,
            103,
            104
        ],
        "comentarios": [],
        "_Pregunta__usuario": "Simon"
    },
    {
        "_id": 5,
        "_Pregunta__titulo": "\"Least Astonishment\" and the Mutable Default Argument",
        "_Pregunta__fecha": "2021-07-30 23:36:37Z",
        "_Pregunta__descripcion": "\n                \nAnyone tinkering with Python long enough has been bitten (or torn to pieces) by the following issue:\ndef foo(a=[]):\n    a.append(5)\n    return a\n\nPython novices would expect this function to always return a list with only one element: [5]. The result is instead very different, and very astonishing (for a novice):\n>>> foo()\n[5]\n>>> foo()\n[5, 5]\n>>> foo()\n[5, 5, 5]\n>>> foo()\n[5, 5, 5, 5]\n>>> foo()\n\nA manager of mine once had his first encounter with this feature, and called it \"a dramatic design flaw\" of the language. I replied that the behavior had an underlying explanation, and it is indeed very puzzling and unexpected if you don't understand the internals. However, I was not able to answer (to myself) the following question: what is the reason for binding the default argument at function definition, and not at function execution? I doubt the experienced behavior has a practical use (who really used static variables in C, without breeding bugs?)\nEdit:\nBaczek made an interesting example. Together with most of your comments and Utaal's in particular, I elaborated further:\n>>> def a():\n...     print(\"a executed\")\n...     return []\n... \n>>>            \n>>> def b(x=a()):\n...     x.append(5)\n...     print(x)\n... \na executed\n>>> b()\n[5]\n>>> b()\n[5, 5]\n\nTo me, it seems that the design decision was relative to where to put the scope of parameters: inside the function, or \"together\" with it?\nDoing the binding inside the function would mean that x is effectively bound to the specified default when the function is called, not defined, something that would present a deep flaw: the def line would be \"hybrid\" in the sense that part of the binding (of the function object) would happen at definition, and part (assignment of default parameters) at function invocation time.\nThe actual behavior is more consistent: everything of that line gets evaluated when that line is executed, meaning at function definition.\n    ",
        "_Pregunta__votes": 2947,
        "_Pregunta__tags": [
            "least-astonishment",
            "language-design",
            "python",
            "default-parameters"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 105,
            "_Respuesta__fecha": "2021-07-30 23:41:21Z",
            "_Respuesta__descripcion": "\nActually, this is not a design flaw, and it is not because of internals or performance.\nIt comes simply from the fact that functions in Python are first-class objects, and not only a piece of code.\nAs soon as you think of it this way, then it completely makes sense: a function is an object being evaluated on its definition; default parameters are kind of \"member data\" and therefore their state may change from one call to the other - exactly as in any other object.\nIn any case, Effbot has a very nice explanation of the reasons for this behavior in Default Parameter Values in Python.\nI found it very clear, and I really suggest reading it for a better knowledge of how function objects work.\n    ",
            "_Respuesta__votes": 1761,
            "comentarios": [
                {
                    "_id": 112,
                    "_Comentario__descripcion": "To anyone reading the above answer, I strongly recommend you take the time to read through the linked Effbot article. As well as all the other useful info, the part on how this language feature can be used for result caching/memoisation is very handy to know!",
                    "_Comentario__fecha": "2011-10-14 00:05:52Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Cam Jackson"
                },
                {
                    "_id": 113,
                    "_Comentario__descripcion": "Even if it's a first-class object, one might still envision a design where the code for each default value is stored along with the object and re-evaluated each time the function is called. I'm not saying that would be better, just that functions being first-class objects does not fully preclude it.",
                    "_Comentario__fecha": "2013-01-11 10:55:25Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "gerrit"
                },
                {
                    "_id": 114,
                    "_Comentario__descripcion": "Sorry, but anything considered \"The biggest WTF in Python\" is most definitely a design flaw.  This is a source of bugs for everyone at some point, because no one expects that behavior at first - which means it should not have been designed that way to begin with.  I don't care what hoops they had to jump through, they should have designed Python so that default arguments are non-static.",
                    "_Comentario__fecha": "2013-06-07 21:28:27Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "BlueRaja - Danny Pflughoeft"
                },
                {
                    "_id": 115,
                    "_Comentario__descripcion": "Whether or not it's a design flaw, your answer seems to imply that this behaviour is somehow necessary, natural and obvious given that functions are first-class objects, and that simply isn't the case. Python has closures. If you replace the default argument with an assignment on the first line of the function, it evaluates the expression each call (potentially using names declared in an enclosing scope). There is no reason at all that it wouldn't be possible or reasonable to have default arguments evaluated each time the function is called in exactly the same way.",
                    "_Comentario__fecha": "2014-01-08 22:16:13Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Mark Amery"
                },
                {
                    "_id": 116,
                    "_Comentario__descripcion": "The design doesn't directly follow from functions are objects. In your paradigm, the proposal would be to implement functions' default values as properties rather than attributes.",
                    "_Comentario__fecha": "2014-05-03 20:46:09Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "bukzor"
                }
            ],
            "_Respuesta__usuario": "rob"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            106,
            107,
            108,
            109,
            110,
            111,
            112,
            113,
            114,
            115,
            116,
            117,
            118,
            119,
            120,
            121,
            122,
            123,
            124,
            125,
            126,
            127,
            128,
            129,
            130,
            131,
            132,
            133,
            134,
            135
        ],
        "comentarios": [
            {
                "_id": 195,
                "_Comentario__descripcion": "Complementary question - Good uses for mutable default arguments",
                "_Comentario__fecha": "2012-02-06 20:54:07Z, License: CC BY-SA 3.0",
                "_Comentario__usuario": "Jonathan"
            },
            {
                "_id": 196,
                "_Comentario__descripcion": "I have not doubt mutable arguments violate least astonishment principle for an average person, and I have seen beginners stepping there, then heroically replacing mailing lists with mailing tuples. Nevertheless mutable arguments are still in line with Python Zen (Pep 20) and falls into \"obvious for Dutch\" (understood/exploited by hard core python programmers) clause.  The recommended  workaround with doc string is the best, yet resistance to doc strings and any (written) docs is not so uncommon nowadays. Personally, I would prefer a decorator (say @fixed_defaults).",
                "_Comentario__fecha": "2017-04-06 16:04:44Z, License: CC BY-SA 3.0",
                "_Comentario__usuario": "Serge"
            },
            {
                "_id": 197,
                "_Comentario__descripcion": "My argument when I come across this is:  \"Why do you need to create a function that returns a mutable that could optionally be a mutable you would pass to the function?  Either it alters a mutable or creates a new one.  Why do you need to do both with one function?  And why should the interpreter be rewritten to allow you to do that without adding three lines to your code?\" Because we are talking about rewriting the way the interpreter handles function definitions and evocations here.  That's a lot to do for a barely necessary use case.",
                "_Comentario__fecha": "2017-06-01 21:22:20Z, License: CC BY-SA 3.0",
                "_Comentario__usuario": "Alan Leuthard"
            },
            {
                "_id": 198,
                "_Comentario__descripcion": "\"Python novices would expect this function to always return a list with only one element: [5].\" I'm a Python novice, and I wouldn't expect this, because obviously foo([1]) will return [1, 5], not [5]. What you meant to say is that a novice would expect the function called with no parameter will always return [5].",
                "_Comentario__fecha": "2017-07-06 16:08:22Z, License: CC BY-SA 3.0",
                "_Comentario__usuario": "symplectomorphic"
            },
            {
                "_id": 199,
                "_Comentario__descripcion": "This question asks \"Why did this [the wrong way] get implemented so?\" It doesn't ask \"What's the right way?\", which is covered by [Why does using arg=None fix Python's mutable default argument issue?]*(stackoverflow.com/questions/10676729/\u2026). New users are almost always less interested in the former and much more in the latter, so that's sometimes a very useful link/dupe to cite.",
                "_Comentario__fecha": "2019-04-21 08:48:07Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "smci"
            }
        ],
        "_Pregunta__usuario": "Stefano Borini"
    },
    {
        "_id": 6,
        "_Pregunta__titulo": "List of lists changes reflected across sublists unexpectedly",
        "_Pregunta__fecha": "2021-06-18 16:29:25Z",
        "_Pregunta__descripcion": "\n                \nI needed to create a list of lists in Python, so I typed the following:\nmy_list = [[1] * 4] * 3\n\nThe list looked like this:\n[[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]  \n\nThen I changed one of the innermost values:\nmy_list[0][0] = 5\n\nNow my list looks like this:\n[[5, 1, 1, 1], [5, 1, 1, 1], [5, 1, 1, 1]]  \n\nwhich is not what I wanted or expected. Can someone please explain what's going on, and how to get around it?\n    ",
        "_Pregunta__votes": 794,
        "_Pregunta__tags": [
            "nested-lists",
            "python",
            "list",
            "mutable"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 136,
            "_Respuesta__fecha": "2020-01-18 21:04:41Z",
            "_Respuesta__descripcion": "\nWhen you write [x]*3 you get, essentially, the list [x, x, x]. That is, a list with 3 references to the same x. When you then modify this single x it is visible via all three references to it:\n\nx = [1] * 4\nl = [x] * 3\nprint(f\"id(x): {id(x)}\")\n# id(x): 140560897920048\nprint(\n    f\"id(l[0]): {id(l[0])}\\n\"\n    f\"id(l[1]): {id(l[1])}\\n\"\n    f\"id(l[2]): {id(l[2])}\"\n)\n# id(l[0]): 140560897920048\n# id(l[1]): 140560897920048\n# id(l[2]): 140560897920048\n\nx[0] = 42\nprint(f\"x: {x}\")\n# x: [42, 1, 1, 1]\nprint(f\"l: {l}\")\n# l: [[42, 1, 1, 1], [42, 1, 1, 1], [42, 1, 1, 1]]\n\n\nTo fix it, you need to make sure that you create a new list at each position. One way to do it is\n\n[[1]*4 for _ in range(3)]\n\n\nwhich will reevaluate [1]*4 each time instead of evaluating it once and making 3 references to 1 list.\n\n\n\nYou might wonder why * can't make independent objects the way the list comprehension does. That's because the multiplication operator * operates on objects, without seeing expressions. When you use * to multiply [[1] * 4] by 3, * only sees the 1-element list [[1] * 4] evaluates to, not the [[1] * 4 expression text. * has no idea how to make copies of that element, no idea how to reevaluate [[1] * 4], and no idea you even want copies, and in general, there might not even be a way to copy the element.\n\nThe only option * has is to make new references to the existing sublist instead of trying to make new sublists. Anything else would be inconsistent or require major redesigning of fundamental language design decisions.\n\nIn contrast, a list comprehension reevaluates the element expression on every iteration. [[1] * 4 for n in range(3)] reevaluates [1] * 4 every time for the same reason [x**2 for x in range(3)] reevaluates x**2 every time. Every evaluation of [1] * 4 generates a new list, so the list comprehension does what you wanted.\n\nIncidentally, [1] * 4 also doesn't copy the elements of [1], but that doesn't matter, since integers are immutable. You can't do something like 1.value = 2 and turn a 1 into a 2.\n    ",
            "_Respuesta__votes": 686,
            "comentarios": [
                {
                    "_id": 200,
                    "_Comentario__descripcion": "I am surprised that no body points out  that, the answer here is misleading. [x]*3 store 3 references like [x, x, x] is only right when x is mutable. This does't work for e.g. a=[4]*3, where after a[0]=5, a=[5,4,4].",
                    "_Comentario__fecha": "2015-05-22 00:16:41Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Allanqunzi"
                },
                {
                    "_id": 201,
                    "_Comentario__descripcion": "Technically, it's still correct. [4]*3 is essentially equivalent to x = 4; [x, x, x]. It's true, though, that this will never cause any problem since 4 is immutable. Also, your other example isn't really a different case. a = [x]*3; a[0] = 5 won't cause problems even if x is mutable, since you're not modifying x, only modifying a. I wouldn't describe my answer as misleading or incorrect - you just can't shoot yourself in the foot if you're dealing with immutable objects.",
                    "_Comentario__fecha": "2015-05-22 08:04:09Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "CAdaker"
                },
                {
                    "_id": 202,
                    "_Comentario__descripcion": "@Allanqunzi you are wrong. Do x = 1000; lst = [x]*2; lst[0] is lst[1] -> True. Python does not distinguish between mutable and immutable objects here whatsoever.",
                    "_Comentario__fecha": "2016-04-17 18:08:26Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "timgeb"
                }
            ],
            "_Respuesta__usuario": "CAdaker"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            137,
            138,
            139,
            140,
            141,
            142,
            143,
            144,
            145,
            146,
            147,
            148,
            149,
            150,
            151,
            152,
            153
        ],
        "comentarios": [],
        "_Pregunta__usuario": "Charles Anderson"
    },
    {
        "_id": 7,
        "_Pregunta__titulo": "List changes unexpectedly after assignment. Why is this and how can I prevent it?",
        "_Pregunta__fecha": "2021-05-11 21:32:23Z",
        "_Pregunta__descripcion": "\n                \nWhile using new_list = my_list, any modifications to new_list changes my_list every time. Why is this, and how can I clone or copy the list to prevent it?\n    ",
        "_Pregunta__votes": 2914,
        "_Pregunta__tags": [
            "list",
            "reference",
            "copy",
            "clone",
            "python"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 154,
            "_Respuesta__fecha": "2020-03-09 01:52:34Z",
            "_Respuesta__descripcion": "\nWith new_list = my_list, you don't actually have two lists. The assignment just copies the reference to the list, not the actual list, so both new_list and my_list refer to the same list after the assignment.\n\nTo actually copy the list, you have various possibilities:\n\n\nYou can use the builtin list.copy() method (available since Python 3.3):\n\nnew_list = old_list.copy()\n\nYou can slice it: \n\nnew_list = old_list[:]\n\n\nAlex Martelli's opinion (at least back in 2007) about this is, that it is a weird syntax and it does not make sense to use it ever. ;) (In his opinion, the next one is more readable).\nYou can use the built in list() function:\n\nnew_list = list(old_list)\n\nYou can use generic copy.copy():\n\nimport copy\nnew_list = copy.copy(old_list)\n\n\nThis is a little slower than list() because it has to find out the datatype of old_list first.\nIf the list contains objects and you want to copy them as well, use generic copy.deepcopy():\n\nimport copy\nnew_list = copy.deepcopy(old_list)\n\n\nObviously the slowest and most memory-needing method, but sometimes unavoidable.\n\n\nExample:\n\nimport copy\n\nclass Foo(object):\n    def __init__(self, val):\n         self.val = val\n\n    def __repr__(self):\n        return 'Foo({!r})'.format(self.val)\n\nfoo = Foo(1)\n\na = ['foo', foo]\nb = a.copy()\nc = a[:]\nd = list(a)\ne = copy.copy(a)\nf = copy.deepcopy(a)\n\n# edit orignal list and instance \na.append('baz')\nfoo.val = 5\n\nprint('original: %r\\nlist.copy(): %r\\nslice: %r\\nlist(): %r\\ncopy: %r\\ndeepcopy: %r'\n      % (a, b, c, d, e, f))\n\n\nResult:\n\noriginal: ['foo', Foo(5), 'baz']\nlist.copy(): ['foo', Foo(5)]\nslice: ['foo', Foo(5)]\nlist(): ['foo', Foo(5)]\ncopy: ['foo', Foo(5)]\ndeepcopy: ['foo', Foo(1)]\n\n    ",
            "_Respuesta__votes": 3690,
            "comentarios": [
                {
                    "_id": 215,
                    "_Comentario__descripcion": "As @Georgy points out correctly in the answer below, any changes to the new_list values will also change the values in my_list. So actually the copy.deepcopy() method is the only real copy without reference to the original list and it's values.",
                    "_Comentario__fecha": "2020-12-21 17:27:56Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "moojen"
                },
                {
                    "_id": 216,
                    "_Comentario__descripcion": "@Erri I think you made a mistake. I didn't post any answers or comments here :)",
                    "_Comentario__fecha": "2020-12-21 17:33:34Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "Georgy"
                },
                {
                    "_id": 217,
                    "_Comentario__descripcion": "You're right, it was edited by you, but posted by @cryo Sorry for the mixup!",
                    "_Comentario__fecha": "2020-12-21 17:52:36Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "moojen"
                },
                {
                    "_id": 218,
                    "_Comentario__descripcion": "Which one is fastest?",
                    "_Comentario__fecha": "2021-05-04 18:10:13Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "zzz777"
                },
                {
                    "_id": 219,
                    "_Comentario__descripcion": "I was having the same issue with a list of json (each element of a list was a json) and the only one that worked was new_list = copy.deepcopy(old_list) ; I'm writing this since anyone can encounter the same issue. Thanks!",
                    "_Comentario__fecha": "2021-05-11 15:23:44Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "Tom"
                }
            ],
            "_Respuesta__usuario": "Felix Kling"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            155,
            156,
            157,
            158,
            159,
            160,
            161,
            162,
            163,
            164,
            165,
            166,
            167,
            168,
            169,
            170,
            171,
            172,
            173,
            174,
            175,
            176
        ],
        "comentarios": [],
        "_Pregunta__usuario": "aF."
    },
    {
        "_id": 8,
        "_Pregunta__titulo": "How can I pivot a dataframe?",
        "_Pregunta__fecha": "2021-07-31 18:10:56Z",
        "_Pregunta__descripcion": "\n                \n\nWhat is pivot?\nHow do I pivot?\nIs this a pivot?\nLong format to wide format?\n\nI've seen a lot of questions that ask about pivot tables.  Even if they don't know that they are asking about pivot tables, they usually are.  It is virtually impossible to write a canonical question and answer that encompasses all aspects of pivoting...\n... But I'm going to give it a go.\n\nThe problem with existing questions and answers is that often the question is focused on a nuance that the OP has trouble generalizing in order to use a number of the existing good answers.  However, none of the answers attempt to give a comprehensive explanation (because it's a daunting task)\nLook a few examples from my Google Search\n\nHow to pivot a dataframe in Pandas?\n\n\nGood question and answer.  But the answer only answers the specific question with little explanation.\n\n\npandas pivot table to data frame\n\n\nIn this question, the OP is concerned with the output of the pivot.  Namely how the columns look.  OP wanted it to look like R.  This isn't very helpful for pandas users.\n\n\npandas pivoting a dataframe, duplicate rows\n\n\nAnother decent question but the answer focuses on one method, namely pd.DataFrame.pivot\n\nSo whenever someone searches for pivot they get sporadic results that are likely not going to answer their specific question.\n\nSetup\nYou may notice that I conspicuously named my columns and relevant column values to correspond with how I'm going to pivot in the answers below.\nimport numpy as np\nimport pandas as pd\nfrom numpy.core.defchararray import add\n\nnp.random.seed([3,1415])\nn = 20\n\ncols = np.array(['key', 'row', 'item', 'col'])\narr1 = (np.random.randint(5, size=(n, 4)) // [2, 1, 2, 1]).astype(str)\n\ndf = pd.DataFrame(\n    add(cols, arr1), columns=cols\n).join(\n    pd.DataFrame(np.random.rand(n, 2).round(2)).add_prefix('val')\n)\nprint(df)\n\n     key   row   item   col  val0  val1\n0   key0  row3  item1  col3  0.81  0.04\n1   key1  row2  item1  col2  0.44  0.07\n2   key1  row0  item1  col0  0.77  0.01\n3   key0  row4  item0  col2  0.15  0.59\n4   key1  row0  item2  col1  0.81  0.64\n5   key1  row2  item2  col4  0.13  0.88\n6   key2  row4  item1  col3  0.88  0.39\n7   key1  row4  item1  col1  0.10  0.07\n8   key1  row0  item2  col4  0.65  0.02\n9   key1  row2  item0  col2  0.35  0.61\n10  key2  row0  item2  col1  0.40  0.85\n11  key2  row4  item1  col2  0.64  0.25\n12  key0  row2  item2  col3  0.50  0.44\n13  key0  row4  item1  col4  0.24  0.46\n14  key1  row3  item2  col3  0.28  0.11\n15  key0  row3  item1  col1  0.31  0.23\n16  key0  row0  item2  col3  0.86  0.01\n17  key0  row4  item0  col3  0.64  0.21\n18  key2  row2  item2  col0  0.13  0.45\n19  key0  row2  item0  col4  0.37  0.70\n\nQuestion(s)\n\nWhy do I get ValueError: Index contains duplicate entries, cannot reshape\n\nHow do I pivot df such that the col values are columns, row values are the index, and mean of val0 are the values?\n col   col0   col1   col2   col3  col4\n row\n row0  0.77  0.605    NaN  0.860  0.65\n row2  0.13    NaN  0.395  0.500  0.25\n row3   NaN  0.310    NaN  0.545   NaN\n row4   NaN  0.100  0.395  0.760  0.24\n\n\nHow do I pivot df such that the col values are columns, row values are the index, mean of val0 are the values, and missing values are 0?\n col   col0   col1   col2   col3  col4\n row\n row0  0.77  0.605  0.000  0.860  0.65\n row2  0.13  0.000  0.395  0.500  0.25\n row3  0.00  0.310  0.000  0.545  0.00\n row4  0.00  0.100  0.395  0.760  0.24\n\n\nCan I get something other than mean, like maybe sum?\n col   col0  col1  col2  col3  col4\n row\n row0  0.77  1.21  0.00  0.86  0.65\n row2  0.13  0.00  0.79  0.50  0.50\n row3  0.00  0.31  0.00  1.09  0.00\n row4  0.00  0.10  0.79  1.52  0.24\n\n\nCan I do more that one aggregation at a time?\n        sum                          mean\n col   col0  col1  col2  col3  col4  col0   col1   col2   col3  col4\n row\n row0  0.77  1.21  0.00  0.86  0.65  0.77  0.605  0.000  0.860  0.65\n row2  0.13  0.00  0.79  0.50  0.50  0.13  0.000  0.395  0.500  0.25\n row3  0.00  0.31  0.00  1.09  0.00  0.00  0.310  0.000  0.545  0.00\n row4  0.00  0.10  0.79  1.52  0.24  0.00  0.100  0.395  0.760  0.24\n\n\nCan I aggregate over multiple value columns?\n       val0                             val1\n col   col0   col1   col2   col3  col4  col0   col1  col2   col3  col4\n row\n row0  0.77  0.605  0.000  0.860  0.65  0.01  0.745  0.00  0.010  0.02\n row2  0.13  0.000  0.395  0.500  0.25  0.45  0.000  0.34  0.440  0.79\n row3  0.00  0.310  0.000  0.545  0.00  0.00  0.230  0.00  0.075  0.00\n row4  0.00  0.100  0.395  0.760  0.24  0.00  0.070  0.42  0.300  0.46\n\n\nCan Subdivide by multiple columns?\n item item0             item1                         item2\n col   col2  col3  col4  col0  col1  col2  col3  col4  col0   col1  col3  col4\n row\n row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.605  0.86  0.65\n row2  0.35  0.00  0.37  0.00  0.00  0.44  0.00  0.00  0.13  0.000  0.50  0.13\n row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.000  0.28  0.00\n row4  0.15  0.64  0.00  0.00  0.10  0.64  0.88  0.24  0.00  0.000  0.00  0.00\n\n\nOr\n item      item0             item1                         item2\n col        col2  col3  col4  col0  col1  col2  col3  col4  col0  col1  col3  col4\n key  row\n key0 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.86  0.00\n      row2  0.00  0.00  0.37  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.50  0.00\n      row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.00  0.00  0.00\n      row4  0.15  0.64  0.00  0.00  0.00  0.00  0.00  0.24  0.00  0.00  0.00  0.00\n key1 row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.81  0.00  0.65\n      row2  0.35  0.00  0.00  0.00  0.00  0.44  0.00  0.00  0.00  0.00  0.00  0.13\n      row3  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.28  0.00\n      row4  0.00  0.00  0.00  0.00  0.10  0.00  0.00  0.00  0.00  0.00  0.00  0.00\n key2 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.40  0.00  0.00\n      row2  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.13  0.00  0.00  0.00\n      row4  0.00  0.00  0.00  0.00  0.00  0.64  0.88  0.00  0.00  0.00  0.00  0.00\n\n\nCan I aggregate the frequency in which the column and rows occur together, aka \"cross tabulation\"?\n col   col0  col1  col2  col3  col4\n row\n row0     1     2     0     1     1\n row2     1     0     2     1     2\n row3     0     1     0     2     0\n row4     0     1     2     2     1\n\n\nHow do I convert a DataFrame from long to wide by pivoting on ONLY two columns? Given,\nnp.random.seed([3, 1415])\ndf2 = pd.DataFrame({'A': list('aaaabbbc'), 'B': np.random.choice(15, 8)})\ndf2\n   A   B\n0  a   0\n1  a  11\n2  a   2\n3  a  11\n4  b  10\n5  b  10\n6  b  14\n7  c   7\n\nThe expected should look something like\n      a     b    c\n0   0.0  10.0  7.0\n1  11.0  10.0  NaN\n2   2.0  14.0  NaN\n3  11.0   NaN  NaN\n\n\nHow do I flatten the multiple index to single index after pivot?\nFrom\n   1  2\n   1  1  2\na  2  1  1\nb  2  1  0\nc  1  0  0\n\nTo\n   1|1  2|1  2|2\na    2    1    1\nb    2    1    0\nc    1    0    0\n\n\n\n    ",
        "_Pregunta__votes": 474,
        "_Pregunta__tags": [
            "pandas",
            "pandas-groupby",
            "group-by",
            "pivot",
            "python"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 177,
            "_Respuesta__fecha": "2021-08-07 11:42:55Z",
            "_Respuesta__descripcion": "\nWe start by answering the first question:\nQuestion 1\n\nWhy do I get ValueError: Index contains duplicate entries, cannot reshape\n\nThis occurs because pandas is attempting to reindex either a columns or index object with duplicate entries.  There are varying methods to use that can perform a pivot.  Some of them are not well suited to when there are duplicates of the keys in which it is being asked to pivot on.  For example.  Consider pd.DataFrame.pivot.  I know there are duplicate entries that share the row and col values:\ndf.duplicated(['row', 'col']).any()\n\nTrue\n\nSo when I pivot using\ndf.pivot(index='row', columns='col', values='val0')\n\nI get the error mentioned above.  In fact, I get the same error when I try to perform the same task with:\ndf.set_index(['row', 'col'])['val0'].unstack()\n\nHere is a list of idioms we can use to pivot\n\npd.DataFrame.groupby + pd.DataFrame.unstack\n\nGood general approach for doing just about any type of pivot\nYou specify all columns that will constitute the pivoted row levels and column levels in one group by.  You follow that by selecting the remaining columns you want to aggregate and the function(s) you want to perform the aggregation.  Finally, you unstack the levels that you want to be in the column index.\n\n\npd.DataFrame.pivot_table\n\nA glorified version of groupby with more intuitive API.  For many people, this is the preferred approach.  And is the intended approach by the developers.\nSpecify row level, column levels, values to be aggregated, and function(s) to perform aggregations.\n\n\npd.DataFrame.set_index + pd.DataFrame.unstack\n\nConvenient and intuitive for some (myself included).  Cannot handle duplicate grouped keys.\nSimilar to the groupby paradigm, we specify all columns that will eventually be either row or column levels and set those to be the index.  We then unstack the levels we want in the columns.  If either the remaining index levels or column levels are not unique, this method will fail.\n\n\npd.DataFrame.pivot\n\nVery similar to set_index in that it shares the duplicate key limitation.  The API is very limited as well.  It only takes scalar values for index, columns, values.\nSimilar to the pivot_table method in that we select rows, columns, and values on which to pivot.  However, we cannot aggregate and if either rows or columns are not unique, this method will fail.\n\n\npd.crosstab\n\nThis a specialized version of pivot_table and in its purest form is the most intuitive way to perform several tasks.\n\n\npd.factorize + np.bincount\n\nThis is a highly advanced technique that is very obscure but is very fast.  It cannot be used in all circumstances, but when it can be used and you are comfortable using it, you will reap the performance rewards.\n\n\npd.get_dummies + pd.DataFrame.dot\n\nI use this for cleverly performing cross tabulation.\n\n\n\n\nExamples\nWhat I'm going to do for each subsequent answer and question is to answer it using pd.DataFrame.pivot_table.  Then I'll provide alternatives to perform the same task.\nQuestion 3\n\nHow do I pivot df such that the col values are columns, row values are the index, mean of val0 are the values, and missing values are 0?\n\n\npd.DataFrame.pivot_table\n\nfill_value is not set by default.  I tend to set it appropriately.  In this case I set it to 0.  Notice I skipped question 2 as it's the same as this answer without the fill_value\n\naggfunc='mean' is the default and I didn't have to set it.  I included it to be explicit.\n    df.pivot_table(\n        values='val0', index='row', columns='col',\n        fill_value=0, aggfunc='mean')\n\n    col   col0   col1   col2   col3  col4\n    row\n    row0  0.77  0.605  0.000  0.860  0.65\n    row2  0.13  0.000  0.395  0.500  0.25\n    row3  0.00  0.310  0.000  0.545  0.00\n    row4  0.00  0.100  0.395  0.760  0.24\n\n\n\n\npd.DataFrame.groupby\n  df.groupby(['row', 'col'])['val0'].mean().unstack(fill_value=0)\n\n\npd.crosstab\n  pd.crosstab(\n      index=df['row'], columns=df['col'],\n      values=df['val0'], aggfunc='mean').fillna(0)\n\n\n\n\nQuestion 4\n\nCan I get something other than mean, like maybe sum?\n\n\npd.DataFrame.pivot_table\n  df.pivot_table(\n      values='val0', index='row', columns='col',\n      fill_value=0, aggfunc='sum')\n\n  col   col0  col1  col2  col3  col4\n  row\n  row0  0.77  1.21  0.00  0.86  0.65\n  row2  0.13  0.00  0.79  0.50  0.50\n  row3  0.00  0.31  0.00  1.09  0.00\n  row4  0.00  0.10  0.79  1.52  0.24\n\n\npd.DataFrame.groupby\n  df.groupby(['row', 'col'])['val0'].sum().unstack(fill_value=0)\n\n\npd.crosstab\n  pd.crosstab(\n      index=df['row'], columns=df['col'],\n      values=df['val0'], aggfunc='sum').fillna(0)\n\n\n\n\nQuestion 5\n\nCan I do more that one aggregation at a time?\n\nNotice that for pivot_table and crosstab I needed to pass list of callables.  On the other hand, groupby.agg is able to take strings for a limited number of special functions.  groupby.agg would also have taken the same callables we passed to the others, but it is often more efficient to leverage the string function names as there are efficiencies to be gained.\n\npd.DataFrame.pivot_table\n  df.pivot_table(\n      values='val0', index='row', columns='col',\n      fill_value=0, aggfunc=[np.size, np.mean])\n\n       size                      mean\n  col  col0 col1 col2 col3 col4  col0   col1   col2   col3  col4\n  row\n  row0    1    2    0    1    1  0.77  0.605  0.000  0.860  0.65\n  row2    1    0    2    1    2  0.13  0.000  0.395  0.500  0.25\n  row3    0    1    0    2    0  0.00  0.310  0.000  0.545  0.00\n  row4    0    1    2    2    1  0.00  0.100  0.395  0.760  0.24\n\n\npd.DataFrame.groupby\n  df.groupby(['row', 'col'])['val0'].agg(['size', 'mean']).unstack(fill_value=0)\n\n\npd.crosstab\n  pd.crosstab(\n      index=df['row'], columns=df['col'],\n      values=df['val0'], aggfunc=[np.size, np.mean]).fillna(0, downcast='infer')\n\n\n\n\nQuestion 6\n\nCan I aggregate over multiple value columns?\n\n\npd.DataFrame.pivot_table we pass values=['val0', 'val1'] but we could've left that off completely\n  df.pivot_table(\n      values=['val0', 'val1'], index='row', columns='col',\n      fill_value=0, aggfunc='mean')\n\n        val0                             val1\n  col   col0   col1   col2   col3  col4  col0   col1  col2   col3  col4\n  row\n  row0  0.77  0.605  0.000  0.860  0.65  0.01  0.745  0.00  0.010  0.02\n  row2  0.13  0.000  0.395  0.500  0.25  0.45  0.000  0.34  0.440  0.79\n  row3  0.00  0.310  0.000  0.545  0.00  0.00  0.230  0.00  0.075  0.00\n  row4  0.00  0.100  0.395  0.760  0.24  0.00  0.070  0.42  0.300  0.46\n\n\npd.DataFrame.groupby\n  df.groupby(['row', 'col'])['val0', 'val1'].mean().unstack(fill_value=0)\n\n\n\n\nQuestion 7\n\nCan Subdivide by multiple columns?\n\n\npd.DataFrame.pivot_table\n  df.pivot_table(\n      values='val0', index='row', columns=['item', 'col'],\n      fill_value=0, aggfunc='mean')\n\n  item item0             item1                         item2\n  col   col2  col3  col4  col0  col1  col2  col3  col4  col0   col1  col3  col4\n  row\n  row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.605  0.86  0.65\n  row2  0.35  0.00  0.37  0.00  0.00  0.44  0.00  0.00  0.13  0.000  0.50  0.13\n  row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.000  0.28  0.00\n  row4  0.15  0.64  0.00  0.00  0.10  0.64  0.88  0.24  0.00  0.000  0.00  0.00\n\n\npd.DataFrame.groupby\n  df.groupby(\n      ['row', 'item', 'col']\n  )['val0'].mean().unstack(['item', 'col']).fillna(0).sort_index(1)\n\n\n\n\nQuestion 8\n\nCan Subdivide by multiple columns?\n\n\npd.DataFrame.pivot_table\n  df.pivot_table(\n      values='val0', index=['key', 'row'], columns=['item', 'col'],\n      fill_value=0, aggfunc='mean')\n\n  item      item0             item1                         item2\n  col        col2  col3  col4  col0  col1  col2  col3  col4  col0  col1  col3  col4\n  key  row\n  key0 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.86  0.00\n       row2  0.00  0.00  0.37  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.50  0.00\n       row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.00  0.00  0.00\n       row4  0.15  0.64  0.00  0.00  0.00  0.00  0.00  0.24  0.00  0.00  0.00  0.00\n  key1 row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.81  0.00  0.65\n       row2  0.35  0.00  0.00  0.00  0.00  0.44  0.00  0.00  0.00  0.00  0.00  0.13\n       row3  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.28  0.00\n       row4  0.00  0.00  0.00  0.00  0.10  0.00  0.00  0.00  0.00  0.00  0.00  0.00\n  key2 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.40  0.00  0.00\n       row2  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.13  0.00  0.00  0.00\n       row4  0.00  0.00  0.00  0.00  0.00  0.64  0.88  0.00  0.00  0.00  0.00  0.00\n\n\npd.DataFrame.groupby\n  df.groupby(\n      ['key', 'row', 'item', 'col']\n  )['val0'].mean().unstack(['item', 'col']).fillna(0).sort_index(1)\n\n\npd.DataFrame.set_index because the set of keys are unique for both rows and columns\n  df.set_index(\n      ['key', 'row', 'item', 'col']\n  )['val0'].unstack(['item', 'col']).fillna(0).sort_index(1)\n\n\n\n\nQuestion 9\n\nCan I aggregate the frequency in which the column and rows occur together, aka \"cross tabulation\"?\n\n\npd.DataFrame.pivot_table\n  df.pivot_table(index='row', columns='col', fill_value=0, aggfunc='size')\n\n      col   col0  col1  col2  col3  col4\n  row\n  row0     1     2     0     1     1\n  row2     1     0     2     1     2\n  row3     0     1     0     2     0\n  row4     0     1     2     2     1\n\n\npd.DataFrame.groupby\n  df.groupby(['row', 'col'])['val0'].size().unstack(fill_value=0)\n\n\npd.crosstab\n  pd.crosstab(df['row'], df['col'])\n\n\npd.factorize + np.bincount\n  # get integer factorization `i` and unique values `r`\n  # for column `'row'`\n  i, r = pd.factorize(df['row'].values)\n  # get integer factorization `j` and unique values `c`\n  # for column `'col'`\n  j, c = pd.factorize(df['col'].values)\n  # `n` will be the number of rows\n  # `m` will be the number of columns\n  n, m = r.size, c.size\n  # `i * m + j` is a clever way of counting the\n  # factorization bins assuming a flat array of length\n  # `n * m`.  Which is why we subsequently reshape as `(n, m)`\n  b = np.bincount(i * m + j, minlength=n * m).reshape(n, m)\n  # BTW, whenever I read this, I think 'Bean, Rice, and Cheese'\n  pd.DataFrame(b, r, c)\n\n        col3  col2  col0  col1  col4\n  row3     2     0     0     1     0\n  row2     1     2     1     0     2\n  row0     1     0     1     2     1\n  row4     2     2     0     1     1\n\n\npd.get_dummies\n  pd.get_dummies(df['row']).T.dot(pd.get_dummies(df['col']))\n\n        col0  col1  col2  col3  col4\n  row0     1     2     0     1     1\n  row2     1     0     2     1     2\n  row3     0     1     0     2     0\n  row4     0     1     2     2     1\n\n\n\n\nQuestion 10\n\nHow do I convert a DataFrame from long to wide by pivoting on ONLY two\ncolumns?\n\n\nDataFrame.pivot\nThe first step is to assign a number to each row - this number will be the row index of that value in the pivoted result. This is done using GroupBy.cumcount:\n  df2.insert(0, 'count', df2.groupby('A').cumcount())\n  df2\n\n     count  A   B\n  0      0  a   0\n  1      1  a  11\n  2      2  a   2\n  3      3  a  11\n  4      0  b  10\n  5      1  b  10\n  6      2  b  14\n  7      0  c   7\n\nThe second step is to use the newly created column as the index to call DataFrame.pivot.\n  df2.pivot(*df2)\n  # df2.pivot(index='count', columns='A', values='B')\n\n  A         a     b    c\n  count\n  0       0.0  10.0  7.0\n  1      11.0  10.0  NaN\n  2       2.0  14.0  NaN\n  3      11.0   NaN  NaN\n\n\nDataFrame.pivot_table\nWhereas DataFrame.pivot only accepts columns, DataFrame.pivot_table also accepts arrays, so the GroupBy.cumcount can be passed directly as the index without creating an explicit column.\n  df2.pivot_table(index=df2.groupby('A').cumcount(), columns='A', values='B')\n\n  A         a     b    c\n  0       0.0  10.0  7.0\n  1      11.0  10.0  NaN\n  2       2.0  14.0  NaN\n  3      11.0   NaN  NaN\n\n\n\n\nQuestion 11\n\nHow do I flatten the multiple index to single index after pivot\n\nIf columns type object with string join\ndf.columns = df.columns.map('|'.join)\n\nelse format\ndf.columns = df.columns.map('{0[0]}|{0[1]}'.format)\n\n    ",
            "_Respuesta__votes": 373,
            "comentarios": [
                {
                    "_id": 243,
                    "_Comentario__descripcion": "Could you please consider extending official docs?",
                    "_Comentario__fecha": "2017-12-15 10:31:13Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "MaxU"
                },
                {
                    "_id": 244,
                    "_Comentario__descripcion": "what happened with the answer to Question #10? I get KeyError: 'A'. Is there more to the answer?",
                    "_Comentario__fecha": "2019-09-27 18:06:51Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "Monica Heddneck"
                },
                {
                    "_id": 245,
                    "_Comentario__descripcion": "@MonicaHeddneck I'll review it again and update if necessary.  However, 'A' is assuming there is a column 'A' in your dataframe to group by.",
                    "_Comentario__fecha": "2019-09-27 20:19:45Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "piRSquared"
                },
                {
                    "_id": 246,
                    "_Comentario__descripcion": "it is not necessary to insert the column in question 10, it can be passed directly as an argument in the pivot table",
                    "_Comentario__fecha": "2020-04-01 18:03:56Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "ansev"
                },
                {
                    "_id": 247,
                    "_Comentario__descripcion": "@MonicaHeddneck I believe the references to df should be changed to df2. If you were following along like I was df is the earlier dataframe created.",
                    "_Comentario__fecha": "2020-04-14 06:16:50Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "CopOnTheRun"
                }
            ],
            "_Respuesta__usuario": "piRSquared"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            178,
            179,
            180
        ],
        "comentarios": [],
        "_Pregunta__usuario": "piRSquared"
    },
    {
        "_id": 9,
        "_Pregunta__titulo": "Pandas Merging 101",
        "_Pregunta__fecha": "2021-07-31 17:38:31Z",
        "_Pregunta__descripcion": "\n                \n\nHow can I perform a (INNER| (LEFT|RIGHT|FULL) OUTER) JOIN with pandas?\nHow do I add NaNs for missing rows after a merge?\nHow do I get rid of NaNs after merging?\nCan I merge on the index?\nHow do I merge multiple DataFrames?\nCross join with pandas\nmerge? join? concat? update? Who? What? Why?!\n\n... and more. I've seen these recurring questions asking about various facets of the pandas merge functionality. Most of the information regarding merge and its various use cases today is fragmented across dozens of badly worded, unsearchable posts. The aim here is to collate some of the more important points for posterity.\nThis Q&A is meant to be the next installment in a series of helpful user guides on common pandas idioms (see this post on pivoting, and this post on concatenation, which I will be touching on, later).\nPlease note that this post is not meant to be a replacement for the documentation, so please read that as well! Some of the examples are taken from there.\n\nTable of Contents\nFor ease of access.\n\nMerging basics - basic types of joins (read this first)\n\nIndex-based joins\n\nGeneralizing to multiple DataFrames\n\nCross join\n\n\n    ",
        "_Pregunta__votes": 622,
        "_Pregunta__tags": [
            "merge",
            "python",
            "pandas",
            "concatenation",
            "join"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 181,
            "_Respuesta__fecha": "2021-07-31 17:38:01Z",
            "_Respuesta__descripcion": "\nThis post aims to give readers a primer on SQL-flavored merging with Pandas, how to use it, and when not to use it.\nIn particular, here's what this post will go through:\n\nThe basics - types of joins (LEFT, RIGHT, OUTER, INNER)\n\nmerging with different column names\nmerging with multiple columns\navoiding duplicate merge key column in output\n\n\n\nWhat this post (and other posts by me on this thread) will not go through:\n\nPerformance-related discussions and timings (for now). Mostly notable mentions of better alternatives, wherever appropriate.\nHandling suffixes, removing extra columns, renaming outputs, and other specific use cases. There are other (read: better) posts that deal with that, so figure it out!\n\n\nNote\nMost examples default to INNER JOIN operations while demonstrating various features, unless otherwise specified.\nFurthermore, all the DataFrames here can be copied and replicated so\nyou can play with them. Also, see this\npost\non how to read DataFrames from your clipboard.\nLastly, all visual representation of JOIN operations have been hand-drawn using Google Drawings. Inspiration from here.\n\n\n\nEnough talk - just show me how to use merge!\nSetup & Basics\nnp.random.seed(0)\nleft = pd.DataFrame({'key': ['A', 'B', 'C', 'D'], 'value': np.random.randn(4)})\nright = pd.DataFrame({'key': ['B', 'D', 'E', 'F'], 'value': np.random.randn(4)})\n\nleft\n\n  key     value\n0   A  1.764052\n1   B  0.400157\n2   C  0.978738\n3   D  2.240893\n\nright\n\n  key     value\n0   B  1.867558\n1   D -0.977278\n2   E  0.950088\n3   F -0.151357\n\nFor the sake of simplicity, the key column has the same name (for now).\nAn INNER JOIN is represented by\n\n\nNote\nThis, along with the forthcoming figures all follow this convention:\n\nblue indicates rows that are present in the merge result\nred indicates rows that are excluded from the result (i.e., removed)\ngreen indicates missing values that are replaced with NaNs in the result\n\n\nTo perform an INNER JOIN, call merge on the left DataFrame, specifying the right DataFrame and the join key (at the very least) as arguments.\nleft.merge(right, on='key')\n# Or, if you want to be explicit\n# left.merge(right, on='key', how='inner')\n\n  key   value_x   value_y\n0   B  0.400157  1.867558\n1   D  2.240893 -0.977278\n\nThis returns only rows from left and right which share a common key (in this example, \"B\" and \"D).\nA LEFT OUTER JOIN, or LEFT JOIN  is represented by\n\nThis can be performed by specifying how='left'.\nleft.merge(right, on='key', how='left')\n\n  key   value_x   value_y\n0   A  1.764052       NaN\n1   B  0.400157  1.867558\n2   C  0.978738       NaN\n3   D  2.240893 -0.977278\n\nCarefully note the placement of NaNs here. If you specify how='left', then only keys from left are used, and missing data from right is replaced by NaN.\nAnd similarly, for a RIGHT OUTER JOIN, or RIGHT JOIN which is...\n\n...specify how='right':\nleft.merge(right, on='key', how='right')\n\n  key   value_x   value_y\n0   B  0.400157  1.867558\n1   D  2.240893 -0.977278\n2   E       NaN  0.950088\n3   F       NaN -0.151357\n\nHere, keys from right are used, and missing data from left is replaced by NaN.\nFinally, for the FULL OUTER JOIN, given by\n\nspecify how='outer'.\nleft.merge(right, on='key', how='outer')\n\n  key   value_x   value_y\n0   A  1.764052       NaN\n1   B  0.400157  1.867558\n2   C  0.978738       NaN\n3   D  2.240893 -0.977278\n4   E       NaN  0.950088\n5   F       NaN -0.151357\n\nThis uses the keys from both frames, and NaNs are inserted for missing rows in both.\nThe documentation summarizes these various merges nicely:\n\n\nOther JOINs - LEFT-Excluding, RIGHT-Excluding, and FULL-Excluding/ANTI JOINs\nIf you need LEFT-Excluding JOINs and RIGHT-Excluding JOINs in two steps.\nFor LEFT-Excluding JOIN, represented as\n\nStart by performing a LEFT OUTER JOIN and then filtering (excluding!) rows coming from left only,\n(left.merge(right, on='key', how='left', indicator=True)\n     .query('_merge == \"left_only\"')\n     .drop('_merge', 1))\n\n  key   value_x  value_y\n0   A  1.764052      NaN\n2   C  0.978738      NaN\n\nWhere,\nleft.merge(right, on='key', how='left', indicator=True)\n\n  key   value_x   value_y     _merge\n0   A  1.764052       NaN  left_only\n1   B  0.400157  1.867558       both\n2   C  0.978738       NaN  left_only\n3   D  2.240893 -0.977278       both\nAnd similarly, for a RIGHT-Excluding JOIN,\n\n(left.merge(right, on='key', how='right', indicator=True)\n     .query('_merge == \"right_only\"')\n     .drop('_merge', 1))\n\n  key  value_x   value_y\n2   E      NaN  0.950088\n3   F      NaN -0.151357\nLastly, if you are required to do a merge that only retains keys from the left or right, but not both (IOW, performing an ANTI-JOIN),\n\nYou can do this in similar fashion\u2014\n(left.merge(right, on='key', how='outer', indicator=True)\n     .query('_merge != \"both\"')\n     .drop('_merge', 1))\n\n  key   value_x   value_y\n0   A  1.764052       NaN\n2   C  0.978738       NaN\n4   E       NaN  0.950088\n5   F       NaN -0.151357\n\n\nDifferent names for key columns\nIf the key columns are named differently\u2014for example, left has keyLeft, and right has keyRight instead of key\u2014then you will have to specify left_on and right_on as arguments instead of on:\nleft2 = left.rename({'key':'keyLeft'}, axis=1)\nright2 = right.rename({'key':'keyRight'}, axis=1)\n\nleft2\n\n  keyLeft     value\n0       A  1.764052\n1       B  0.400157\n2       C  0.978738\n3       D  2.240893\n\nright2\n\n  keyRight     value\n0        B  1.867558\n1        D -0.977278\n2        E  0.950088\n3        F -0.151357\n\n\nleft2.merge(right2, left_on='keyLeft', right_on='keyRight', how='inner')\n\n  keyLeft   value_x keyRight   value_y\n0       B  0.400157        B  1.867558\n1       D  2.240893        D -0.977278\n\n\nAvoiding duplicate key column in output\nWhen merging on keyLeft from left and keyRight from right, if you only want either of the keyLeft or keyRight (but not both) in the output, you can start by setting the index as a preliminary step.\nleft3 = left2.set_index('keyLeft')\nleft3.merge(right2, left_index=True, right_on='keyRight')\n\n    value_x keyRight   value_y\n0  0.400157        B  1.867558\n1  2.240893        D -0.977278\n\nContrast this with the output of the command just before (that is, the output of left2.merge(right2, left_on='keyLeft', right_on='keyRight', how='inner')), you'll notice keyLeft is missing. You can figure out what column to keep based on which frame's index is set as the key. This may matter when, say, performing some OUTER JOIN operation.\n\nMerging only a single column from one of the DataFrames\nFor example, consider\nright3 = right.assign(newcol=np.arange(len(right)))\nright3\n  key     value  newcol\n0   B  1.867558       0\n1   D -0.977278       1\n2   E  0.950088       2\n3   F -0.151357       3\n\nIf you are required to merge only \"new_val\" (without any of the other columns), you can usually just subset columns before merging:\nleft.merge(right3[['key', 'newcol']], on='key')\n\n  key     value  newcol\n0   B  0.400157       0\n1   D  2.240893       1\n\nIf you're doing a LEFT OUTER JOIN, a more performant solution would involve map:\n# left['newcol'] = left['key'].map(right3.set_index('key')['newcol']))\nleft.assign(newcol=left['key'].map(right3.set_index('key')['newcol']))\n\n  key     value  newcol\n0   A  1.764052     NaN\n1   B  0.400157     0.0\n2   C  0.978738     NaN\n3   D  2.240893     1.0\n\nAs mentioned, this is similar to, but faster than\nleft.merge(right3[['key', 'newcol']], on='key', how='left')\n\n  key     value  newcol\n0   A  1.764052     NaN\n1   B  0.400157     0.0\n2   C  0.978738     NaN\n3   D  2.240893     1.0\n\n\nMerging on multiple columns\nTo join on more than one column, specify a list for on (or left_on and right_on, as appropriate).\nleft.merge(right, on=['key1', 'key2'] ...)\n\nOr, in the event the names are different,\nleft.merge(right, left_on=['lkey1', 'lkey2'], right_on=['rkey1', 'rkey2'])\n\n\nOther useful merge* operations and functions\n\nMerging a DataFrame with Series on index: See this answer.\n\nBesides merge, DataFrame.update and DataFrame.combine_first are also used in certain cases to update one DataFrame with another.\n\npd.merge_ordered is a useful function for ordered JOINs.\n\npd.merge_asof (read: merge_asOf) is useful for approximate joins.\n\n\nThis section only covers the very basics, and is designed to only whet your appetite. For more examples and cases, see the documentation on merge, join, and concat as well as the links to the function specifications.\n\n\nContinue Reading\nJump to other topics in Pandas Merging 101 to continue learning:\n\nMerging basics - basic types of joins *\n\nIndex-based joins\n\nGeneralizing to multiple DataFrames\n\nCross join\n\n\n*You are here.\n    ",
            "_Respuesta__votes": 880,
            "comentarios": [
                {
                    "_id": 254,
                    "_Comentario__descripcion": "If anyone is confused by the table of contents at the end of each post, I split up this massive answer into 4 separate ones, 3 on this question and 1 on another. The way it was setup previously made it harder to reference folks to specific topics. This allows you to bookmark separate topics easily now!",
                    "_Comentario__fecha": "2020-12-17 10:17:28Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "cs95"
                },
                {
                    "_id": 255,
                    "_Comentario__descripcion": "This is an awesome resource! The only question I still have is why call it merge instead of join, and join instead of merge?",
                    "_Comentario__fecha": "2021-04-08 22:31:14Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "ThatNewGuy"
                }
            ],
            "_Respuesta__usuario": "cs95"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            182,
            183,
            184,
            185,
            186,
            187
        ],
        "comentarios": [],
        "_Pregunta__usuario": "cs95"
    },
    {
        "_id": 10,
        "_Pregunta__titulo": "How to remove items from a list while iterating?",
        "_Pregunta__fecha": "2018-02-28 14:25:52Z",
        "_Pregunta__descripcion": "\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        This question's answers are a community effort. Edit existing answers to improve this post. It is not currently accepting new answers or interactions.\n                        \n                    \n                \n            \n        \n\n\n    \n\nI'm iterating over a list of tuples in Python, and am attempting to remove them if they meet certain criteria. \n\nfor tup in somelist:\n    if determine(tup):\n         code_to_remove_tup\n\n\nWhat should I use in place of code_to_remove_tup? I can't figure out how to remove the item in this fashion.\n    ",
        "_Pregunta__votes": 933,
        "_Pregunta__tags": [
            "python",
            "iteration"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 188,
            "_Respuesta__fecha": "2021-03-19 21:52:42Z",
            "_Respuesta__descripcion": "\nYou can use a list comprehension to create a new list containing only the elements you don't want to remove:\nsomelist = [x for x in somelist if not determine(x)]\n\nOr, by assigning to the slice somelist[:], you can mutate the existing list to contain only the items you want:\nsomelist[:] = [x for x in somelist if not determine(x)]\n\nThis approach could be useful if there are other references to somelist that need to reflect the changes.\nInstead of a comprehension, you could also use itertools. In Python 2:\nfrom itertools import ifilterfalse\nsomelist[:] = ifilterfalse(determine, somelist)\n\nOr in Python 3:\nfrom itertools import filterfalse\nsomelist[:] = filterfalse(determine, somelist)\n\n    ",
            "_Respuesta__votes": 954,
            "comentarios": [
                {
                    "_id": 263,
                    "_Comentario__descripcion": "Can you make it faster if you know only a few will be deleted, i.e., only delete those and leave the others in-place rather than re-writing them?",
                    "_Comentario__fecha": "2011-04-20 19:25:57Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "highBandWidth"
                },
                {
                    "_id": 264,
                    "_Comentario__descripcion": "What if my list is huge and can't afford making a copy?",
                    "_Comentario__fecha": "2014-11-15 23:43:18Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "jpcgt"
                },
                {
                    "_id": 265,
                    "_Comentario__descripcion": "@jpcgt You should use somelist[:] = (x for x in somelist if determine(x)) this will create generator that may not create any unnecessary copies.",
                    "_Comentario__fecha": "2015-04-29 14:54:28Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Rostislav Kondratenko"
                },
                {
                    "_id": 266,
                    "_Comentario__descripcion": "@RostislavKondratenko: list_ass_slice() function that implements somelist[:]= calls PySequence_Fast() internally. This function always returns a list i.e., @Alex Martelli's solution that already uses a list instead of a generator is most probably more efficient",
                    "_Comentario__fecha": "2015-05-07 20:48:28Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "jfs"
                },
                {
                    "_id": 267,
                    "_Comentario__descripcion": "Would you care to explain what the differences are between assigning the list comprehension to the list and list clone please? Wouldn't the original list somelist be mutated in both methods?",
                    "_Comentario__fecha": "2018-09-24 19:06:14Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "Bowen Liu"
                }
            ],
            "_Respuesta__usuario": "David Raznick"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            189,
            190,
            191,
            192,
            193,
            194,
            195,
            196,
            197,
            198,
            199,
            200,
            201,
            202,
            203,
            204,
            205,
            206,
            207,
            208,
            209,
            210,
            211,
            212,
            213
        ],
        "comentarios": [
            {
                "_id": 307,
                "_Comentario__descripcion": "Most answers on this page don't really explain why removing elements while iterating over a list produces strange results, but the accepted answer in this question does, and is probably a better dupe for beginners who encounter this issue for the first time.",
                "_Comentario__fecha": "2019-12-06 23:34:07Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "ggorlen"
            }
        ],
        "_Pregunta__usuario": "lfaraone"
    },
    {
        "_id": 11,
        "_Pregunta__titulo": "How to make a flat list out of a list of lists",
        "_Pregunta__fecha": "2021-07-31 18:17:31Z",
        "_Pregunta__descripcion": "\n                \nIs there a shortcut to make a simple list out of a list of lists in Python?\nI can do it in a for loop, but is there some cool \"one-liner\"?\nI tried it with functools.reduce():\nfrom functools import reduce\nl = [[1, 2, 3], [4, 5, 6], [7], [8, 9]]\nreduce(lambda x, y: x.extend(y), l)\n\nBut I get this error:\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"<stdin>\", line 1, in <lambda>\nAttributeError: 'NoneType' object has no attribute 'extend'\n\n    ",
        "_Pregunta__votes": 4242,
        "_Pregunta__tags": [
            "multidimensional-array",
            "python",
            "list",
            "flatten"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 214,
            "_Respuesta__fecha": "2021-07-04 18:40:40Z",
            "_Respuesta__descripcion": "\nGiven a list of lists t,\nflat_list = [item for sublist in t for item in sublist]\n\nwhich means:\nflat_list = []\nfor sublist in t:\n    for item in sublist:\n        flat_list.append(item)\n\nis faster than the shortcuts posted so far. (t is the list to flatten.)\nHere is the corresponding function:\ndef flatten(t):\n    return [item for sublist in t for item in sublist]\n\nAs evidence, you can use the timeit module in the standard library:\n$ python -mtimeit -s't=[[1,2,3],[4,5,6], [7], [8,9]]*99' '[item for sublist in t for item in sublist]'\n10000 loops, best of 3: 143 usec per loop\n$ python -mtimeit -s't=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'sum(t, [])'\n1000 loops, best of 3: 969 usec per loop\n$ python -mtimeit -s't=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'reduce(lambda x,y: x+y,t)'\n1000 loops, best of 3: 1.1 msec per loop\n\nExplanation: the shortcuts based on + (including the implied use in sum) are, of necessity, O(T**2) when there are T sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So, for simplicity and without actual loss of generality, say you have T sublists of k items each: the first k items are copied back and forth T-1 times, the second k items T-2 times, and so on; total number of copies is k times the sum of x for x from 1 to T excluded, i.e., k * (T**2)/2.\nThe list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.\n    ",
            "_Respuesta__votes": 6026,
            "comentarios": [
                {
                    "_id": 308,
                    "_Comentario__descripcion": "I tried a test with the same data, using itertools.chain.from_iterable :         $ python -mtimeit -s'from itertools import chain; l=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'list(chain.from_iterable(l))'.   It runs a bit more than twice as fast as the nested list comprehension that's the fastest of the alternatives shown here.",
                    "_Comentario__fecha": "2010-10-15 01:21:33Z, License: CC BY-SA 2.5",
                    "_Comentario__usuario": "intuited"
                },
                {
                    "_id": 309,
                    "_Comentario__descripcion": "I found the syntax hard to understand until I realized you can think of it exactly like nested for loops.  for sublist in l: for item in sublist: yield item",
                    "_Comentario__fecha": "2011-07-27 16:43:18Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Rob Crowell"
                },
                {
                    "_id": 310,
                    "_Comentario__descripcion": "[leaf for tree in forest for leaf in tree] might be easier to comprehend and apply.",
                    "_Comentario__fecha": "2013-08-29 01:38:20Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "John Mee"
                },
                {
                    "_id": 311,
                    "_Comentario__descripcion": "@RobCrowell Same here. To me the list comprehension one doesn't read right, something feels off about it - I always seem to get it wrong and end up googling. To me this reads right [leaf for leaf in tree for tree in forest]. I wish this is how it was. I am sure I am missing something about the grammar here, and I would appreciate if anyone could point that out.",
                    "_Comentario__fecha": "2021-07-12 17:19:14Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "S\u043d\u0430\u0111\u043e\u0448\u0192\u0430\u04fd"
                },
                {
                    "_id": 312,
                    "_Comentario__descripcion": "I kept looking here every time I wanted to flatten a list, but this gif is what drove it home: i.stack.imgur.com/0GoV5.gif",
                    "_Comentario__fecha": "2021-08-11 12:04:22Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "Gilthans"
                }
            ],
            "_Respuesta__usuario": "Alex Martelli"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            215,
            216,
            217,
            218,
            219,
            220,
            221,
            222,
            223,
            224,
            225,
            226,
            227,
            228,
            229,
            230,
            231,
            232,
            233,
            234
        ],
        "comentarios": [
            {
                "_id": 355,
                "_Comentario__descripcion": "There's an in-depth discussion of this here: rightfootin.blogspot.com/2006/09/more-on-python-flatten.html, discussing several methods of flattening arbitrarily nested lists of lists. An interesting read!",
                "_Comentario__fecha": "2009-06-04 20:41:13Z, License: CC BY-SA 2.5",
                "_Comentario__usuario": "RichieHindle"
            },
            {
                "_id": 356,
                "_Comentario__descripcion": "Some other answers are better but the reason yours fails is that the 'extend' method always returns None. For a list with length 2, it will work but return None. For a longer list, it will consume the first 2 args, which returns None. It then continues with None.extend(<third arg>), which causes this erro",
                "_Comentario__fecha": "2013-06-11 21:48:27Z, License: CC BY-SA 3.0",
                "_Comentario__usuario": "mehtunguh"
            },
            {
                "_id": 357,
                "_Comentario__descripcion": "stackoverflow.com/questions/50259290/\u2026   (this article explain the difference between an np.flatten() and a tf.flatten() use (static vs dynamic) ndarray.",
                "_Comentario__fecha": "2020-12-18 16:48:11Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "Golden Lion"
            }
        ],
        "_Pregunta__usuario": "Emma"
    },
    {
        "_id": 12,
        "_Pregunta__titulo": "How can I read inputs as numbers?",
        "_Pregunta__fecha": "2019-04-28 01:05:10Z",
        "_Pregunta__descripcion": "\n                    \n            \n        \n            \n                    \n                        \n                    \n                \n                    \n                        This question's answers are a community effort. Edit existing answers to improve this post. It is not currently accepting new answers or interactions.\n                        \n                    \n                \n            \n        \n\n\n    \n\nWhy are x and y strings instead of ints in the below code?\n\n(Note: in Python 2.x use raw_input(). In Python 3.x use input(). raw_input() was renamed to input() in Python 3.x)\n\nplay = True\n\nwhile play:\n\n    x = input(\"Enter a number: \")\n    y = input(\"Enter a number: \")\n\n    print(x + y)\n    print(x - y)\n    print(x * y)\n    print(x / y)\n    print(x % y)\n\n    if input(\"Play again? \") == \"no\":\n        play = False\n\n    ",
        "_Pregunta__votes": 261,
        "_Pregunta__tags": [
            "python-3.x",
            "int",
            "input",
            "python",
            "python-2.7"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 235,
            "_Respuesta__fecha": "2021-01-28 13:45:16Z",
            "_Respuesta__descripcion": "\nSolution\nSince Python 3, input returns a string which you have to explicitly convert to ints, with int, like this\nx = int(input(\"Enter a number: \"))\ny = int(input(\"Enter a number: \"))\n\nYou can accept numbers of any base and convert them directly to base-10 with the int function, like this\n>>> data = int(input(\"Enter a number: \"), 8)\nEnter a number: 777\n>>> data\n511\n>>> data = int(input(\"Enter a number: \"), 16)\nEnter a number: FFFF\n>>> data\n65535\n>>> data = int(input(\"Enter a number: \"), 2)\nEnter a number: 10101010101\n>>> data\n1365\n\nThe second parameter tells what is the base of the numbers entered and then internally it understands and converts it. If the entered data is wrong it will throw a ValueError.\n>>> data = int(input(\"Enter a number: \"), 2)\nEnter a number: 1234\nTraceback (most recent call last):\n  File \"<input>\", line 1, in <module>\nValueError: invalid literal for int() with base 2: '1234'\n\nFor values that can have a fractional component, the type would be float rather than int:\nx = float(input(\"Enter a number:\"))\n\nDifferences between Python 2 and 3\nSummary\n\nPython 2's input function evaluated the received data, converting it to an integer implicitly (read the next section to understand the implication), but Python 3's input function does not do that anymore.\nPython 2's equivalent of Python 3's input is the raw_input function.\n\nPython 2.x\nThere were two functions to get user input, called input and raw_input. The difference between them is, raw_input doesn't evaluate the data and returns as it is, in string form. But, input will evaluate whatever you entered and the result of evaluation will be returned. For example,\n>>> import sys\n>>> sys.version\n'2.7.6 (default, Mar 22 2014, 22:59:56) \\n[GCC 4.8.2]'\n>>> data = input(\"Enter a number: \")\nEnter a number: 5 + 17\n>>> data, type(data)\n(22, <type 'int'>)\n\nThe data 5 + 17 is evaluated and the result is 22. When it evaluates the expression 5 + 17, it detects that you are adding two numbers and so the result will also be of the same int type. So, the type conversion is done for free and 22 is returned as the result of input and stored in data variable. You can think of input as the raw_input composed with an eval call.\n>>> data = eval(raw_input(\"Enter a number: \"))\nEnter a number: 5 + 17\n>>> data, type(data)\n(22, <type 'int'>)\n\nNote: you should be careful when you are using input in Python 2.x. I explained why one should be careful when using it, in this answer.\nBut, raw_input doesn't evaluate the input and returns as it is, as a string.\n>>> import sys\n>>> sys.version\n'2.7.6 (default, Mar 22 2014, 22:59:56) \\n[GCC 4.8.2]'\n>>> data = raw_input(\"Enter a number: \")\nEnter a number: 5 + 17\n>>> data, type(data)\n('5 + 17', <type 'str'>)\n\nPython 3.x\nPython 3.x's input and Python 2.x's raw_input are similar and raw_input is not available in Python 3.x.\n>>> import sys\n>>> sys.version\n'3.4.0 (default, Apr 11 2014, 13:05:11) \\n[GCC 4.8.2]'\n>>> data = input(\"Enter a number: \")\nEnter a number: 5 + 17\n>>> data, type(data)\n('5 + 17', <class 'str'>)\n\n    ",
            "_Respuesta__votes": 354,
            "comentarios": [
                {
                    "_id": 358,
                    "_Comentario__descripcion": "Is there any other way, like a function or something so that we dont need to convert to int in 3.x other than doing explicit conversion to int??",
                    "_Comentario__fecha": "2016-04-09 06:19:24Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Shreyan Mehta"
                },
                {
                    "_id": 359,
                    "_Comentario__descripcion": "@ShreyanMehta eval would work, but don't go for that unless you have pressing reasons.",
                    "_Comentario__fecha": "2016-04-09 07:01:32Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "thefourtheye"
                },
                {
                    "_id": 360,
                    "_Comentario__descripcion": "@thefourtheye at least use ast.literal_eval for that. It does not have the security concerns of eval.",
                    "_Comentario__fecha": "2018-04-06 12:48:28Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "spectras"
                }
            ],
            "_Respuesta__usuario": "thefourtheye"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            236,
            237,
            238,
            239,
            240,
            241,
            242,
            243,
            244,
            245
        ],
        "comentarios": [
            {
                "_id": 367,
                "_Comentario__descripcion": "asking-the-user-for-input-until-they-give-a-valid-response",
                "_Comentario__fecha": "2018-09-13 20:50:23Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "Patrick Artner"
            }
        ],
        "_Pregunta__usuario": "ANON"
    },
    {
        "_id": 13,
        "_Pregunta__titulo": "How do you split a list into evenly sized chunks?",
        "_Pregunta__fecha": "2017-05-23 11:55:11Z",
        "_Pregunta__descripcion": "\n                \nI have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.\n\nI was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.\n\nI was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.\n\nRelated question: What is the most \u201cpythonic\u201d way to iterate over a list in chunks?\n    ",
        "_Pregunta__votes": 2639,
        "_Pregunta__tags": [
            "python",
            "list",
            "chunks",
            "split"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 246,
            "_Respuesta__fecha": "2019-11-28 01:43:27Z",
            "_Respuesta__descripcion": "\nHere's a generator that yields the chunks you want:\n\ndef chunks(lst, n):\n    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]\n\n\n\n\nimport pprint\npprint.pprint(list(chunks(range(10, 75), 10)))\n[[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n [70, 71, 72, 73, 74]]\n\n\n\n\nIf you're using Python 2, you should use xrange() instead of range():\n\ndef chunks(lst, n):\n    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n    for i in xrange(0, len(lst), n):\n        yield lst[i:i + n]\n\n\n\n\nAlso you can simply use list comprehension instead of writing a function, though it's a good idea to encapsulate operations like this in named functions so that your code is easier to understand. Python 3:\n\n[lst[i:i + n] for i in range(0, len(lst), n)]\n\n\nPython 2 version:\n\n[lst[i:i + n] for i in xrange(0, len(lst), n)]\n\n    ",
            "_Respuesta__votes": 3802,
            "comentarios": [
                {
                    "_id": 368,
                    "_Comentario__descripcion": "What happens if we can't tell the length of the list? Try this on itertools.repeat([ 1, 2, 3 ]), e.g.",
                    "_Comentario__fecha": "2008-11-23 12:51:10Z, License: CC BY-SA 2.5",
                    "_Comentario__usuario": "jespern"
                },
                {
                    "_id": 369,
                    "_Comentario__descripcion": "That's an interesting extension to the question, but the original question clearly asked about operating on a list.",
                    "_Comentario__fecha": "2008-11-23 13:53:37Z, License: CC BY-SA 2.5",
                    "_Comentario__usuario": "Ned Batchelder"
                },
                {
                    "_id": 370,
                    "_Comentario__descripcion": "this functions needs to be in the damn standard library",
                    "_Comentario__fecha": "2018-02-04 14:19:55Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "dgan"
                },
                {
                    "_id": 371,
                    "_Comentario__descripcion": "@Calimo: what do you suggest? I hand you a list with 47 elements. How would you like to split it into \"evenly sized chunks\"? The OP accepted the answer, so they are clearly OK with the last differently sized chunk. Perhaps the English phrase is imprecise?",
                    "_Comentario__fecha": "2018-06-14 15:29:23Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "Ned Batchelder"
                },
                {
                    "_id": 372,
                    "_Comentario__descripcion": "Most people will be looking at this for batch processing and rate limiting, so it usually doesn't matter if the last chunk is smaller",
                    "_Comentario__fecha": "2019-07-04 12:46:37Z, License: CC BY-SA 4.0",
                    "_Comentario__usuario": "Alvaro"
                }
            ],
            "_Respuesta__usuario": "Ned Batchelder"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            247,
            248,
            249,
            250,
            251,
            252,
            253,
            254,
            255,
            256,
            257,
            258,
            259,
            260,
            261,
            262,
            263,
            264,
            265,
            266,
            267,
            268,
            269,
            270,
            271,
            272,
            273,
            274,
            275,
            276
        ],
        "comentarios": [
            {
                "_id": 411,
                "_Comentario__descripcion": "Before you post a new answer, consider there are already 60+ answers for this question. Please, make sure that your answer contributes information that is not among existing answers.",
                "_Comentario__fecha": "2020-02-03 12:17:33Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "janniks"
            },
            {
                "_id": 412,
                "_Comentario__descripcion": "simple one at stackoverflow.com/a/66967457/687896",
                "_Comentario__fecha": "2021-04-06 11:13:04Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "Brandt"
            }
        ],
        "_Pregunta__usuario": "jespern"
    },
    {
        "_id": 14,
        "_Pregunta__titulo": "How do I pass a variable by reference?",
        "_Pregunta__fecha": "2017-03-22 16:16:41Z",
        "_Pregunta__descripcion": "\n                \nThe Python documentation seems unclear about whether parameters are passed by reference or value, and the following code produces the unchanged value 'Original'\n\nclass PassByReference:\n    def __init__(self):\n        self.variable = 'Original'\n        self.change(self.variable)\n        print(self.variable)\n\n    def change(self, var):\n        var = 'Changed'\n\n\nIs there something I can do to pass the variable by actual reference?\n    ",
        "_Pregunta__votes": 2951,
        "_Pregunta__tags": [
            "parameter-passing",
            "python",
            "pass-by-reference",
            "reference"
        ],
        "_Pregunta__respuesta_aceptada": {
            "_id": 277,
            "_Respuesta__fecha": "2017-04-03 02:13:38Z",
            "_Respuesta__descripcion": "\nArguments are passed by assignment. The rationale behind this is twofold:\n\n\nthe parameter passed in is actually a reference to an object (but the reference is passed by value)\nsome data types are mutable, but others aren't\n\n\nSo:\n\n\nIf you pass a mutable object into a method, the method gets a reference to that same object and you can mutate it to your heart's delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you're done, the outer reference will still point at the original object. \nIf you pass an immutable object to a method, you still can't rebind the outer reference, and you can't even mutate the object.\n\n\nTo make it even more clear, let's have some examples. \n\nList - a mutable type\n\nLet's try to modify the list that was passed to a method:\n\ndef try_to_change_list_contents(the_list):\n    print('got', the_list)\n    the_list.append('four')\n    print('changed to', the_list)\n\nouter_list = ['one', 'two', 'three']\n\nprint('before, outer_list =', outer_list)\ntry_to_change_list_contents(outer_list)\nprint('after, outer_list =', outer_list)\n\n\nOutput:\n\nbefore, outer_list = ['one', 'two', 'three']\ngot ['one', 'two', 'three']\nchanged to ['one', 'two', 'three', 'four']\nafter, outer_list = ['one', 'two', 'three', 'four']\n\n\nSince the parameter passed in is a reference to outer_list, not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope.\n\nNow let's see what happens when we try to change the reference that was passed in as a parameter:\n\ndef try_to_change_list_reference(the_list):\n    print('got', the_list)\n    the_list = ['and', 'we', 'can', 'not', 'lie']\n    print('set to', the_list)\n\nouter_list = ['we', 'like', 'proper', 'English']\n\nprint('before, outer_list =', outer_list)\ntry_to_change_list_reference(outer_list)\nprint('after, outer_list =', outer_list)\n\n\nOutput:\n\nbefore, outer_list = ['we', 'like', 'proper', 'English']\ngot ['we', 'like', 'proper', 'English']\nset to ['and', 'we', 'can', 'not', 'lie']\nafter, outer_list = ['we', 'like', 'proper', 'English']\n\n\nSince the the_list parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The the_list was a copy of the outer_list reference, and we had the_list point to a new list, but there was no way to change where outer_list pointed.\n\nString - an immutable type\n\nIt's immutable, so there's nothing we can do to change the contents of the string\n\nNow, let's try to change the reference\n\ndef try_to_change_string_reference(the_string):\n    print('got', the_string)\n    the_string = 'In a kingdom by the sea'\n    print('set to', the_string)\n\nouter_string = 'It was many and many a year ago'\n\nprint('before, outer_string =', outer_string)\ntry_to_change_string_reference(outer_string)\nprint('after, outer_string =', outer_string)\n\n\nOutput:\n\nbefore, outer_string = It was many and many a year ago\ngot It was many and many a year ago\nset to In a kingdom by the sea\nafter, outer_string = It was many and many a year ago\n\n\nAgain, since the the_string parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The the_string was a copy of the outer_string reference, and we had the_string point to a new string, but there was no way to change where outer_string pointed.\n\nI hope this clears things up a little.\n\nEDIT: It's been noted that this doesn't answer the question that @David originally asked, \"Is there something I can do to pass the variable by actual reference?\". Let's work on that.\n\nHow do we get around this?\n\nAs @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out:\n\ndef return_a_whole_new_string(the_string):\n    new_string = something_to_do_with_the_old_string(the_string)\n    return new_string\n\n# then you could call it like\nmy_string = return_a_whole_new_string(my_string)\n\n\nIf you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list:\n\ndef use_a_wrapper_to_simulate_pass_by_reference(stuff_to_change):\n    new_string = something_to_do_with_the_old_string(stuff_to_change[0])\n    stuff_to_change[0] = new_string\n\n# then you could call it like\nwrapper = [my_string]\nuse_a_wrapper_to_simulate_pass_by_reference(wrapper)\n\ndo_something_with(wrapper[0])\n\n\nAlthough this seems a little cumbersome.\n    ",
            "_Respuesta__votes": 3174,
            "comentarios": [
                {
                    "_id": 413,
                    "_Comentario__descripcion": "Then the same is in C, when you pass \"by reference\" you're actually passing by value the reference... Define \"by reference\" :P",
                    "_Comentario__fecha": "2009-06-12 11:52:33Z, License: CC BY-SA 2.5",
                    "_Comentario__usuario": "Andrea Ambu"
                },
                {
                    "_id": 414,
                    "_Comentario__descripcion": "I'm not sure I understand your terms. I've been out of the C game for a while, but back when I was in it, there was no \"pass by reference\" - you could pass things, and it was always pass by value, so whatever was in the parameter list was copied. But sometimes the thing was a pointer, which one could follow to the piece of memory (primitive, array, struct, whatever), but you couldn't change the pointer that was copied from the outer scope - when you were done with the function, the original pointer still pointed to the same address. C++ introduced references, which behaved differently.",
                    "_Comentario__fecha": "2009-06-12 12:09:22Z, License: CC BY-SA 2.5",
                    "_Comentario__usuario": "Blair Conrad"
                },
                {
                    "_id": 415,
                    "_Comentario__descripcion": "@Zac Bowling I don't really get how what you're saying is relevant, in a practical sense, to this answer. If a Python newcomer wanted to know about passing by ref/val, then the takeaway from this answer is: 1- You can use the reference that a function receives as its arguments, to modify the 'outside' value of a variable, as long as you don't reassign the parameter to refer to a new object. 2- Assigning to an immutable type will always create a new object, which breaks the reference that you had to the outside variable.",
                    "_Comentario__fecha": "2011-09-08 23:50:34Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Cam Jackson"
                },
                {
                    "_id": 416,
                    "_Comentario__descripcion": "@CamJackson, you need a better example - numbers are also immutable objects in Python. Besides, wouldn't it be true to say that any assignment without subscripting on the left side of the equals will reassign the name to a new object whether it is immutable or not? def Foo(alist): alist = [1,2,3] will not modify the contents of the list from the callers perspective.",
                    "_Comentario__fecha": "2011-11-15 16:46:32Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Mark Ransom"
                },
                {
                    "_id": 417,
                    "_Comentario__descripcion": "-1. The code shown is good, the explanation as to how is completely wrong.  See the answers by DavidCournapeau or DarenThomas for correct explanations as to why.",
                    "_Comentario__fecha": "2012-01-07 06:41:59Z, License: CC BY-SA 3.0",
                    "_Comentario__usuario": "Ethan Furman"
                }
            ],
            "_Respuesta__usuario": "Blair Conrad"
        },
        "_Pregunta__respondida": true,
        "_Pregunta__respuestas": [
            278,
            279,
            280,
            281,
            282,
            283,
            284,
            285,
            286,
            287,
            288,
            289,
            290,
            291,
            292,
            293,
            294,
            295,
            296,
            297,
            298,
            299,
            300,
            301,
            302,
            303,
            304,
            305,
            306,
            307
        ],
        "comentarios": [
            {
                "_id": 472,
                "_Comentario__descripcion": "For a short explanation/clarification see the first answer to this stackoverflow question. As strings are immutable, they won't be changed and a new variable will be created, thus the \"outer\" variable still has the same value.",
                "_Comentario__fecha": "2009-06-12 10:35:53Z, License: CC BY-SA 2.5",
                "_Comentario__usuario": "PhilS"
            },
            {
                "_id": 473,
                "_Comentario__descripcion": "The code in BlairConrad's answer is good, but the explanation provided by DavidCournapeau and DarenThomas is correct.",
                "_Comentario__fecha": "2012-01-07 06:47:10Z, License: CC BY-SA 3.0",
                "_Comentario__usuario": "Ethan Furman"
            },
            {
                "_id": 474,
                "_Comentario__descripcion": "Before reading the selected answer, please consider reading this short text Other languages have \"variables\", Python has \"names\". Think about \"names\" and \"objects\" instead of \"variables\" and \"references\" and you should avoid a lot of similar problems.",
                "_Comentario__fecha": "2012-11-15 00:39:20Z, License: CC BY-SA 3.0",
                "_Comentario__usuario": "lqc"
            },
            {
                "_id": 475,
                "_Comentario__descripcion": "Why does this needlessly use a class? This isn't Java :P",
                "_Comentario__fecha": "2014-10-22 19:19:01Z, License: CC BY-SA 3.0",
                "_Comentario__usuario": "Peter R"
            },
            {
                "_id": 476,
                "_Comentario__descripcion": "New official how of Iqc's link: david.goodger.org/projects/pycon/2007/idiomatic/\u2026",
                "_Comentario__fecha": "2020-06-09 19:56:56Z, License: CC BY-SA 4.0",
                "_Comentario__usuario": "Ray Hulha"
            }
        ],
        "_Pregunta__usuario": "David Sykes"
    }
]